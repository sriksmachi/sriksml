{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Huggingface models on Azure ML\n",
    "\n",
    "This notebook explains how to create an end-to-end lineage for hugging face models on Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, AzureCliCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import AmlCompute, ComputeInstance\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create MLClient\n",
    "def create_ml_client(credential=None):     \n",
    "    if credential is None:\n",
    "        try:\n",
    "            credential = DefaultAzureCredential()\n",
    "            # Check if given credential can get token successfully.\n",
    "            credential.get_token(\"https://management.azure.com/.default\")\n",
    "        except Exception as ex:\n",
    "            # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "            credential = AzureCliCredential()\n",
    "\n",
    "    return MLClient.from_config(credential=credential)\n",
    "\n",
    "# Function to create AML Compute Cluster\n",
    "def create_aml_cluster(ml_client, gpu_cluster_name = \"AmlComputeCluster\", vm_size = \"Standard_NC4as_T4_v3\", min_nodes = 1, max_nodes = 2):\n",
    "    # If you already have a gpu cluster, mention it here. Else will create a new one    \n",
    "    try:\n",
    "        compute = ml_client.compute.get(gpu_cluster_name)\n",
    "        print(\"successfully fetched compute:\", compute.name)\n",
    "    except Exception as ex:\n",
    "        print(\"failed to fetch compute:\", gpu_cluster_name)\n",
    "        print(f\"creating new {vm_size} compute\")\n",
    "        compute = AmlCompute(\n",
    "            name=gpu_cluster_name,\n",
    "            size=vm_size,\n",
    "            min_instances=min_nodes,\n",
    "            max_instances=max_nodes,  # For multi node training set this to an integer value more than 1\n",
    "        )\n",
    "        ml_client.compute.begin_create_or_update(compute).wait()\n",
    "        print(\"successfully created compute:\", compute.name)\n",
    "    return compute\n",
    "\n",
    "def create_aml_node(ml_client, node_name = \"vism-cpu-8c\", vm_size = \"Standard_E4ds_v4\"):\n",
    "    try:\n",
    "        compute = ml_client.compute.get(node_name)\n",
    "        print(\"successfully fetched compute:\", compute.name)\n",
    "    except Exception as ex:\n",
    "        print(\"failed to fetch compute:\", node_name)\n",
    "        print(f\"creating new {vm_size} compute\")\n",
    "        compute = ComputeInstance(\n",
    "            name=node_name,\n",
    "            size=vm_size\n",
    "        )\n",
    "        ml_client.compute.begin_create_or_update(compute).wait()\n",
    "        print(\"successfully created compute:\", compute.name)\n",
    "    return compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create Environment\n",
    "def create_environment(ml_client, env_Name = \"finetune_hf_lora\"):\n",
    "    try:\n",
    "        env = ml_client.environments.get(env_Name, version=\"latest\")\n",
    "        print(\"successfully fetched environment:\", env.name)\n",
    "    except Exception as ex:\n",
    "        print(\"failed to fetch environment:\", env_Name)\n",
    "        print(f\"creating new environment {env_Name}\")\n",
    "        env_docker_context = Environment(\n",
    "            build=BuildContext(path=\"src/env\"),\n",
    "            name=env_Name,\n",
    "            description=\"Environment created from a Docker context.\",\n",
    "        )\n",
    "        ml_client.environments.create_or_update(env_docker_context)\n",
    "        print(\"successfully created environment:\", env_docker_context.name)\n",
    "    return env_docker_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure ML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "# Create Azure ML dataset from local file\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "VERSION = \"1.0\"\n",
    "NAME = \"squad_dev_v1\"\n",
    "def create_dataset(ml_client):\n",
    "    # Create a dataset from local file\n",
    "    dataset = Data(\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        path=\"./data/squad.json\",\n",
    "        description=\"SquAD v1.0 dev dataset\",\n",
    "        name=NAME,\n",
    "        version=VERSION,\n",
    "    )\n",
    "    return ml_client.data.create_or_update(dataset)\n",
    "\n",
    "ml_client = create_ml_client()\n",
    "try:\n",
    "   ml_client.data.get(NAME, VERSION)\n",
    "except:\n",
    "   create_dataset(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure ML pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully fetched compute: AMLComputeCluster\n",
      "successfully fetched compute: vism-cpu-8c\n",
      "failed to fetch environment: finetune_hf_lora\n",
      "creating new environment finetune_hf_lora\n",
      "successfully created environment: finetune_hf_lora\n"
     ]
    }
   ],
   "source": [
    "gpu_cluster_name = \"AmlComputeCluster\"\n",
    "cpu_compute_name = \"vism-cpu-8c\"\n",
    "env_name = \"finetune_hf_lora\"\n",
    "data_asset = ml_client.data.get(NAME, version=VERSION)\n",
    "ml_client = create_ml_client()\n",
    "mlflow_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "compute_cluster = create_aml_cluster(ml_client, gpu_cluster_name = gpu_cluster_name)\n",
    "compute_instance = create_aml_node(ml_client, node_name = cpu_compute_name)\n",
    "env_docker_context = create_environment(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.01 MBs): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12544/12544 [00:00<00:00, 162351.80it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component train_hf_qna_squad_dev_v1 with Version 2024-06-27-05-01-35-8703317 is registered\n"
     ]
    }
   ],
   "source": [
    "training_component = command(\n",
    "    name=\"train_hf_qna_squad_dev_v1\",\n",
    "    display_name=\"Fine tune HF model\",\n",
    "    description=\"Fine tune HF model on Squad dataset for QnA task\",\n",
    "    inputs={\n",
    "        \"data\": Input(mode=InputOutputModes.MOUNT, type=AssetTypes.URI_FILE, destination_path_on_compute=\"data\"),\n",
    "        \"mlflow_tracking_uri\": \"\"\n",
    "    },\n",
    "    outputs=dict(\n",
    "        train_output=Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
    "    ),\n",
    "    # The source folder of the component\n",
    "    code='./src',\n",
    "    command=\"\"\"python train_component.py \\\n",
    "            --data_path ${{inputs.data}} \\\n",
    "            --target_input_length=512 \\\n",
    "            --model_name \"google/flan-t5-small\" \\\n",
    "            --num_epochs 1 \\\n",
    "            --mlflow_tracking_uri \"${{inputs.mlflow_tracking_uri}}\" \\\n",
    "            --target_max_length=100 \\\n",
    "            --train_size=1000\"\"\",\n",
    "    environment=f\"{env_name}@latest\",\n",
    ")\n",
    "\n",
    "training_component = ml_client.create_or_update(training_component.component)\n",
    "print(f\"Component {training_component.name} with Version {training_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(path=data_asset.id, mode=InputOutputModes.MOUNT, type=AssetTypes.URI_FILE, destination_path_on_compute=\"data\")\n",
    "\n",
    "@pipeline(\n",
    "    default_compute=gpu_cluster_name,\n",
    ")\n",
    "def finetune_hfmodels_azureml_pipeline(pipeline_input_data):\n",
    "    \"\"\"E2E Hugging face Q and A model using huggingface, peft, azureml and python sdk.\"\"\"\n",
    "    train_node = training_component(data=pipeline_input_data, mlflow_tracking_uri=mlflow_tracking_uri)\n",
    "    train_node.compute = cpu_compute_name\n",
    "\n",
    "# create a pipeline\n",
    "pipeline_job = finetune_hfmodels_azureml_pipeline(pipeline_input_data=inputs)\n",
    "pipeline_job = ml_client.jobs.create_or_update(pipeline_job, experiment_name=\"finetuning_hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline nice_dream_j74y44grmy created\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Running\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n",
      "Pipeline nice_dream_j74y44grmy status: Canceled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     job_status \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mget(pipeline_job\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_job\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_status\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ml_client.jobs.stream(pipeline_job.name)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(f\"Pipeline {pipeline_job.name} created\")\n",
    "job_status = ml_client.jobs.get(pipeline_job.name)\n",
    "print(f\"Pipeline {pipeline_job.name} status: {job_status.status}\")\n",
    "while job_status.status not in [\"Completed\", \"Failed\", \"Canceled\"]:\n",
    "    job_status = ml_client.jobs.get(pipeline_job.name)\n",
    "    print(f\"Pipeline {pipeline_job.name} status: {job_status.status}\")\n",
    "    time.sleep(30)\n",
    "\n",
    "# ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
