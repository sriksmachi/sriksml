{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U azure-ai-ml>=1.10\n",
    "%pip install -U 'azureml-rag[azure,cognitive_search]>=0.2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.json\n",
    "{\n",
    "    \"subscription_id\": \"6a01260f-39d6-415f-a6c9-cf4fd479cbec\",\n",
    "    \"resource_group\": \"sriks-ml-rg\",\n",
    "    \"workspace_name\": \"sriks-ml-sea\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential, AzureCliCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = AzureCliCredential()\n",
    "\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "experiment_name = \"doc-summarization-hf\"\n",
    "# If you already have a gpu cluster, mention it here. Else will create a new one\n",
    "compute_cluster = \"AMLComputeCluster\"\n",
    "try:\n",
    "    compute = ml_client.compute.get(compute_cluster)\n",
    "    print(\"successfully fetched compute:\", compute.name)\n",
    "except Exception as ex:\n",
    "    print(\"failed to fetch compute:\", compute_cluster)\n",
    "    print(\"creating new Standard_ND40rs_v2 compute\")\n",
    "    compute = AmlCompute(\n",
    "        name=compute_cluster,\n",
    "        size=\"Standard_NC4as_T4_v3\", # Info on Standard_ND40rs_v2 SKU: https://learn.microsoft.com/en-us/azure/virtual-machines/ndv2-series\n",
    "        min_instances=1,\n",
    "        max_instances=2,  # For multi node training set this to an integer value more than 1\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute).wait()\n",
    "    print(\"successfully created compute:\", compute.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "Env_Name = \"finetuning_hf\"\n",
    "env_docker_context = Environment(\n",
    "    build=BuildContext(path=\"env\"),\n",
    "    name=Env_Name,\n",
    "    description=\"Environment created from a Docker context.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    VsCodeJobService,\n",
    "    TensorBoardJobService,\n",
    "    JupyterLabJobService,\n",
    ")\n",
    "\n",
    "job = command(\n",
    "    code=\".\",\n",
    "    command=\"python finetune_hf_models.py \\\n",
    "        --model_name google/flan-t5-small \\\n",
    "        --dataset squad \\\n",
    "        --target_input_length=512 \\\n",
    "        --target_max_length=100 \\\n",
    "        --train_size=1000\",\n",
    "    compute=compute_cluster,\n",
    "    services={\n",
    "      \"My_jupyterlab\": JupyterLabJobService(\n",
    "        nodes=\"all\" # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n",
    "      ),\n",
    "      \"My_vscode\": VsCodeJobService(\n",
    "        nodes=\"all\"\n",
    "      ),\n",
    "      \"My_tensorboard\": TensorBoardJobService(\n",
    "        nodes=\"all\",\n",
    "        log_dir=\"outputs/runs\"  # relative path of Tensorboard logs (same as in your training script)         \n",
    "      ),\n",
    "    },\n",
    "    environment=\"finetuning_hf@latest\",\n",
    "    instance_count=1,  \n",
    "    display_name=\"hf_finetuning\"\n",
    ") # basic environment comes with my workspace\n",
    "job = ml_client.jobs.create_or_update(job)\n",
    "job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
