{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search optimization techniques in AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_service_endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "search_service_key = os.environ[\"AZURE_SEARCH_KEY\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 1024))\n",
    "embedding_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = AzureOpenAI(\n",
    "        azure_deployment=azure_openai_embedding_deployment,\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key\n",
    "    )\n",
    "\n",
    "def get_embeddings(text):\n",
    "    response = embedding.create(input=text, model=embedding_model_name, dimensions=azure_openai_embedding_dimensions)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# def get_quantized_embeddings(text):\n",
    "#     response = openai_client.embeddings.create(input=text, model=embedding_model_name, dimensions=azure_openai_embedding_dimensions)\n",
    "#     return response.data[0].quantized_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "files = os.listdir(data_folder)\n",
    "file_path = os.path.join(data_folder, files[0])\n",
    "pdf_content = PdfReader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'azure_search_manager' has no attribute 'create_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m search_index_client \u001b[38;5;241m=\u001b[39m SearchIndexClient(search_service_endpoint, search_service_key)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, options \u001b[38;5;129;01min\u001b[39;00m indexes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 16\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43masm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_index\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_index_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, dimensions\u001b[38;5;241m=\u001b[39membedding_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m     17\u001b[0m     search_index_client\u001b[38;5;241m.\u001b[39mcreate_or_update_index(index)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated indexes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'azure_search_manager' has no attribute 'create_index'"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "import azureml.vector_optimizations.azure_search_manager as asm\n",
    "\n",
    "indexes = {\n",
    "    \"all-options-with-binary\": {\n",
    "        \"use_binary_compression\": True,\n",
    "        \"use_float16\": True,\n",
    "        \"use_stored\": False,\n",
    "        \"truncation_dimension\": 1024\n",
    "    }\n",
    "}\n",
    "base_index_name = \"movies\"\n",
    "embedding_dimensions = azure_openai_embedding_dimensions\n",
    "search_index_client = SearchIndexClient(search_service_endpoint, search_service_key)\n",
    "for index, options in indexes.items():\n",
    "    index = asm.create_index(f\"{base_index_name}-{index}\", dimensions=embedding_dimensions, **options)\n",
    "    search_index_client.create_or_update_index(index)\n",
    "print(\"Created indexes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Vector:\n",
      "[0.16300752758979797, 0.22726836800575256, -0.20111069083213806, -0.6051528453826904, 0.4125409722328186, -0.10740336775779724, 0.5433188080787659, 0.40219298005104065, -0.3696734309196472, 0.559572160243988]\n",
      "-1.653213620185852 4.231903076171875\n",
      "\n",
      "Scalar Quantized Vector:\n",
      "[79, 81, 63, 45, 90, 67, 95, 89, 56, 96]\n",
      "\n",
      "Binary Quantized Vector:\n",
      "[1, 1, -1, -1, 1, -1, 1, 1, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def fetch_embeddings(query_text: str) -> dict:\n",
    "    # Define the URL and the data payload\n",
    "    endpoint = \"http://localhost:11434/api/embeddings\"\n",
    "    payload = {\n",
    "        \"model\": \"mxbai-embed-large:latest\",\n",
    "        \"prompt\": query_text\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url=endpoint, json=payload)\n",
    "\n",
    "    # Print the response\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def scalar_quantization(input_vector: List[float], quantization_type=np.uint8) -> List[int]:\n",
    "    # Calculate the min and max for each dimension\n",
    "    min_vals = np.min(input_vector, axis=0)\n",
    "    max_vals = np.max(input_vector, axis=0)\n",
    "\n",
    "    print(min_vals, max_vals)\n",
    "\n",
    "    # Calculate scaling factor and zero point for each dimension\n",
    "    scaling_factors = (max_vals - min_vals) / 255.0\n",
    "    zero_points = -min_vals / scaling_factors\n",
    "\n",
    "    # Quantize the embeddings\n",
    "    quantized_embeddings = np.round((input_vector - min_vals) / scaling_factors).astype(quantization_type)\n",
    "\n",
    "    return quantized_embeddings.tolist()\n",
    "\n",
    "\n",
    "def binary_quantization(input_vector: List[float]) -> List[int]:\n",
    "    # Convert embeddings to -1 or 1 based on their sign\n",
    "    binary_embeddings = np.where(np.array(input_vector) >= 0, 1, -1)\n",
    "    return binary_embeddings.tolist()\n",
    "\n",
    "\n",
    "vector_response = fetch_embeddings(\n",
    "    query_text=\"I am doing hard research on the quantization techniques in embeddings and LLM weights \"\n",
    "               \"and its impact on hallucination\")\n",
    "\n",
    "embedding = vector_response['embedding']\n",
    "print('Original Vector:')\n",
    "print(vector_response['embedding'][:10])\n",
    "\n",
    "scalar_quantized_vector = scalar_quantization(input_vector=embedding, quantization_type=np.uint16)\n",
    "print('\\nScalar Quantized Vector:')\n",
    "print(scalar_quantized_vector[:10])\n",
    "\n",
    "binary_quantized_vector = binary_quantization(input_vector=embedding)\n",
    "print('\\nBinary Quantized Vector:')\n",
    "print(binary_quantized_vector[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
