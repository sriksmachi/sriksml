{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install langchain langchain_community\n",
    "# %pip install neo4j\n",
    "# %pip install langchain_openai\n",
    "# %pip install python-dotenv\n",
    "# %pip install chromadb\n",
    "# %pip install \"numpy<2\"\n",
    "# %pip install networkx\n",
    "# %pip install matplotlib\n",
    "# %pip install dowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEO4J_URI'] = 'bolt://localhost:7690'\n",
    "os.environ['NEO4J_USERNAME'] = 'neo4j'\n",
    "os.environ['NEO4J_PASSWORD'] = 'Password@123'\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://sriks-openai.openai.azure.com/\"\n",
    "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-05-01-preview\"\n",
    "# os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"] = \"gpt-4o\"\n",
    "# os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"] = \"text-embedding-ada-002\"\n",
    "\n",
    "# llm = AzureChatOpenAI(\n",
    "#     openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "#     azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"],\n",
    "# )\n",
    "\n",
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "#     azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = [\n",
    "#     {\n",
    "#         \"question\": \"What is the root cause request id 8ff8696695aa73588ac454809741e2ea\",\n",
    "#         \"query\": \"MATCH (n)-[r:DEPENDS_ON]->(m) where n.id <> 'ROOT' OR m.id <> 'ROOT' and r.operationId = 8ff8696695aa73588ac454809741e2ea RETURN n.id, r.duration, r.operation_Name, m.id ORDER BY r.duration DESC LIMIT 3\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"question\": \"what is the longest running operation\",\n",
    "#         \"query\": \"MATCH (n)-[r:DEPENDS_ON]->(m) where n.id <> 'ROOT' OR m.id <> 'ROOT' RETURN n.id, r.duration, r.operation_Name, m.id ORDER BY r.duration DESC LIMIT 3\",\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import GraphCypherQAChain\n",
    "# from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "# from langchain_core.example_selectors import SemanticSimilarityExampleSelector, MaxMarginalRelevanceExampleSelector\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.chains.llm import LLMChain\n",
    "# from langchain.chains.graph_qa.cypher import construct_schema\n",
    "# from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "# from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "# # load human intervention tools\n",
    "# tools = load_tools(\n",
    "#     [\"human\"], llm\n",
    "# )\n",
    "\n",
    "# graph.refresh_schema()\n",
    "\n",
    "# QA_GENERATION_TEMPLATE = \"\"\"\n",
    "#        Task: answer the question you are given based on the context provided.\n",
    "#        Instructions:\n",
    "#         You are an assistant that helps to form nice and human understandable answers. \n",
    "#         Use the context information provided to generate a well organized and comprehensve answer to the user's question. \n",
    "#         When the provided information contains multiple elements, structure your answer as a bulleted or numbered list to enhance clarity and readability.\n",
    "#         You must use the information to construct your answer. \n",
    "#         The provided information is authoritative; do not doubt it or try to use your internal knowledge to correct it. \n",
    "#         Make the answer sound like a response to the question without mentioning that you based the result on the given information. \n",
    "#         If there is no information provided, say that the knowledge base returned empty results.\n",
    "\n",
    "#         Here's the information:\n",
    "#         {context}\n",
    "\n",
    "#         Question: {question}\n",
    "#         Answer:\n",
    "#             \"\"\"\n",
    "# EXAMPLES_PROMPT_TEMPLATE = \"\"\"   \n",
    "#                 Input: {question},\n",
    "#                 Output: {query}\n",
    "#             \"\"\"\n",
    "\n",
    "# qaPrompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=QA_GENERATION_TEMPLATE)\n",
    "\n",
    "# example_prompt = PromptTemplate(input_variables=[\"question\", \"query\"], template=EXAMPLES_PROMPT_TEMPLATE)\n",
    "\n",
    "# cypherPromptTemplate = \"\"\"\n",
    "# You are an expert Neo4j Developer translating user questions into Cypher to answer questions.\n",
    "# Convert the user's question based on the schema.\n",
    "# Instructions: Use only the provided relationship types and properties in the schema.\n",
    "# Do not use any other relationship types or properties that are not provided.\n",
    "# Schema:\n",
    "# {schema}\n",
    "\n",
    "# Note: Do not include any explanations or apologies in your responses.\n",
    "# Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "# Do not include any text except the generated Cypher statement.\n",
    "\n",
    "# Important: In the generated Cypher query, the RETURN statement must explicitly include the property values used in the query's filtering condition, alongside the main information requested from the original question.\n",
    "\n",
    "# Question: {question}\n",
    "# input:\n",
    "# \"\"\"\n",
    "\n",
    "# similaritySelector = SemanticSimilarityExampleSelector.from_examples(\n",
    "#     examples=examples, \n",
    "#     embeddings=embeddings, \n",
    "#     k=1,\n",
    "#     vectorstore_cls=Chroma\n",
    "# )\n",
    "\n",
    "# cypherPrompt = FewShotPromptTemplate(\n",
    "#     example_selector=similaritySelector,\n",
    "#     example_prompt=example_prompt,\n",
    "#     input_variables=[\"question\", \"schema\"], \n",
    "#     prefix=cypherPromptTemplate,\n",
    "#     suffix=\"the question is:{question}\",\n",
    "# )\n",
    "\n",
    "# cypherqachain = GraphCypherQAChain.from_llm(\n",
    "#     llm = llm,\n",
    "#     return_intermediate_steps=True,\n",
    "#     validate_cypher=True,\n",
    "#     graph=graph, \n",
    "#     verbose=True,\n",
    "#     k=3,\n",
    "#     use_function_response=True,\n",
    "#     cypherPrompt=cypherPrompt,\n",
    "#     return_direct=True,\n",
    "#     output_key=\"input\",\n",
    "# ) \n",
    "\n",
    "# schema  = construct_schema(graph.get_structured_schema, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test cypher chain invocation\n",
    "# cypherqachain.invoke({\"query\": \"which nodes has max azure dependencies\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# nx.draw(graph, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Work In Progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAAAQCAYAAABJJRIXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAABJ0AAASdAHeZh94AAADEklEQVR4nO3XXYhVVRQH8N+UUDCIgRBCUdaQERQaBElBNggWBaF9vGnSSwiJGQpBFMsVBD1EKVYYBSNMvQRBPWQlpGTfgRAVfWiKQZGVlWL2YJk97H3seLxXaObOU/3hsO7+s/9n37X2OmvvNXT8+HH/dUxrDzLzdizAPMzFdLwQEUu7wsyciSW4GVfgPBzFpxjDWET8NVlN1e3DhX18+CEiZvXQnI+HcSNm4nu8jIyIX9tzz+hoH8TKGoTv+iza4A48i6vxIdbjJVyO5/BiZg4NQNPgELLH81h3YmaOYCfuwkd4AntxL96vm3EC0zr6+/AtvlYyYnu/CGAXbsGr7d3LzAfqwrfh1urkZDQNDkbEutP8nzaexrlYFREbW+s8Xn18BCsa/qQgRMT2luC0q0TEtj78/szcVBe6XsuhiWj+LWoWLMI+PNVdCndjWWauiYgjnJoJg8If1f45QM1ZmbkUF+AIPsGOiDjWmTda7dZufYmIw5n5rhKk+XiTU2vCpJGZ03BnHb4+QM0sjCvZsh7bsDszF3TmXVrtrj7v2V3tnIYYeBDwqFLotkTEGwPSjGGhEohh5WR5BrPxWmbObc2dUe2hPms1/DkNMdDPITNXYQ2+xLJBaSKiW6A+w4rM/K1q1ylH74QwsEzIzJXYgM8xGhG/TIWmg03VXtfimp2eoTca/mBDDCQImbkaG5UdGo2I/VOh6YGfqh1ucV9VO0dvXFLtiZox6SBk5v3KZeRjxZkfp0LTB/Or3dvimmN+UWae5F9mTse1+B0fNPykgpCZDylFbScWRsSBQWsy87LMHO7Bz8aTdfh8w0fEHmxViuY9XZmSNePNHQGG2g1UZi7G4jqchRuUKL9duQMRsbbOXY7NOKakda9qvC8iNrfePxHNOqX47cA3OIwRpf84G1uwJCKOtjQjeE+5Nb6CL5Sr+qjyGVwTET8387unwzws73AX10f9E2vr74uqPROrezgDb1WnG0xEs105+69UUnlYKWrvKPeG8Yg4qRWOiD2ZeZV/GqiblAZqgx4N1ND/rTR/AzMLREZZTtmpAAAAAElFTkSuQmCC",
      "text/latex": [
       "$\\displaystyle 12250$"
      ],
      "text/plain": [
       "12250"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_df = pd.read_csv('pc.csv')\n",
    "len(pc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>CounterName</th>\n",
       "      <th>avg_CounterValue</th>\n",
       "      <th>ServiceName</th>\n",
       "      <th>InstanceId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/7/2024, 3:00:00.000 pm</td>\n",
       "      <td>cpuUsageNanoCores</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>notification-api</td>\n",
       "      <td>dbcaa474-d058-4f26-ad2b-168a62be0dab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp        CounterName  avg_CounterValue  \\\n",
       "2  12/7/2024, 3:00:00.000 pm  cpuUsageNanoCores          0.000647   \n",
       "\n",
       "        ServiceName                            InstanceId  \n",
       "2  notification-api  dbcaa474-d058-4f26-ad2b-168a62be0dab  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minimize_scale(x):\n",
    "    if x['CounterName'] == 'memoryWorkingSetBytes':\n",
    "        return x['avg_CounterValue'] / 1000000\n",
    "    elif x['CounterName'] == 'cpuUsageNanoCores':\n",
    "        return x['avg_CounterValue'] / 1e9\n",
    "    \n",
    "def parseServiceName(x):\n",
    "    splits = x.split('/')\n",
    "    servicename = splits[-1]\n",
    "    return servicename\n",
    "\n",
    "def parseInstanceId(x):\n",
    "    splits = x.split('/')\n",
    "    instanceid = splits[-2]\n",
    "    return instanceid\n",
    "\n",
    "# reducing the scale of countervalue\n",
    "regex_filter_for_services = 'api'\n",
    "pc_df['avg_CounterValue'] = pc_df['avg_CounterValue'].astype(float) \n",
    "pc_df['avg_CounterValue'] = pc_df.apply(minimize_scale, axis=1)\n",
    "pc_df['ServiceName'] = pc_df['InstanceName'].apply(lambda x: parseServiceName(x))\n",
    "# only keep rows that have services in service name\n",
    "# pc_df = pc_df[pc_df['ServiceName'] in services]\n",
    "pc_df['InstanceId'] = pc_df['InstanceName'].apply(lambda x: parseInstanceId(x))\n",
    "pc_df.drop(columns=['InstanceName'], inplace=True)\n",
    "pc_df.rename(columns={'TimeGenerated [UTC]': 'timestamp'}, inplace=True)\n",
    "# only keep rows that have api in service name\n",
    "# to make it general, we can get the services from the user and then filter based on that\n",
    "pc_df = pc_df[pc_df['ServiceName'].str.contains(regex_filter_for_services)]\n",
    "pc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only CPU Usage\n",
    "cpu_pc_df = pc_df[pc_df['CounterName'].str.contains('cpuUsageNanoCores')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"notification-api\",\"address-api\",\"reports-api\",\"utex-api\",\"note-api\",\"crm-api\",\"people-api\",\"configuration-api\",\"uniquenumbergenerator-api\",\"shift-api\",\"authorization-api\",\"users-api\",\"billing-api\",\"solomon-api\",\"docuware-api\",\"roles-api\",\"v4-api\",\"u2-api\",\"rules-api\",\"payroll-api\",\"fallout-api\",\"ingestion-api\",\"careattend-api\",\"intframework-api\"]\n"
     ]
    }
   ],
   "source": [
    "def format_services_for_cypher(services):\n",
    "   services = cpu_pc_df['ServiceName'].unique().tolist()\n",
    "   services = [f'\"{service}\"' for service in services]\n",
    "   services = \"[\" + \",\".join(services) + \"]\"\n",
    "   return services\n",
    "services = format_services_for_cypher(cpu_pc_df['ServiceName'].unique().tolist())\n",
    "print(services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from neo4j import GraphDatabase\n",
    "import matplotlib\n",
    "\n",
    "driver = GraphDatabase.driver(os.environ['NEO4J_URI'], auth=(\"neo4j\", os.environ['NEO4J_PASSWORD']))\n",
    "\n",
    "def graph_from_cypher(operationId, services):\n",
    "    G = nx.MultiDiGraph()\n",
    "    # write a query to get all nodes except one that contains APIM In node id\n",
    "    # query = \"MATCH\"\n",
    "    query = f\"MATCH (n:cloudRoleName)-[r:DEPENDS_ON]-(m:cloudRoleName) where (r.operationId = '{operationId}' and n.id in {services} or m.id in {services} ) RETURN n, r, m\"\n",
    "    results = driver.session().run(query)\n",
    "    nodes = list(results.graph()._nodes.values())\n",
    "    for node in nodes:\n",
    "        G.add_node(node._properties['id'], labels=node._labels, properties=node._properties)\n",
    "    rels = list(results.graph()._relationships.values())\n",
    "    for rel in rels:\n",
    "        G.add_edge(rel.start_node._properties['id'], rel.end_node._properties['id'], key=rel.element_id, type=rel.type, properties=rel._properties)\n",
    "    return G, nodes, rels\n",
    "\n",
    "graph, nodes, rels = graph_from_cypher(\"792fbcbe80b94771a8bd96c4211312b9\", services)\n",
    "nx.draw(graph, with_labels=True, font_weight='bold')\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rules-api', 'payroll-api', 'people-api', 'authorization-api', 'u2-api', 'v4-api']\n"
     ]
    }
   ],
   "source": [
    "services_in_graph = [node._properties['id'] for node in nodes]\n",
    "print(services_in_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_pc_df = pc_df[pc_df.apply(lambda x: x['ServiceName'] in services_in_graph, axis=1)]\n",
    "len(f_pc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ServiceName</th>\n",
       "      <th>avg_CounterValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/7/2024, 2:10:00.000 pm</td>\n",
       "      <td>authorization-api</td>\n",
       "      <td>195.237478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/7/2024, 2:10:00.000 pm</td>\n",
       "      <td>payroll-api</td>\n",
       "      <td>166.074778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/7/2024, 2:10:00.000 pm</td>\n",
       "      <td>people-api</td>\n",
       "      <td>222.701978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/7/2024, 2:10:00.000 pm</td>\n",
       "      <td>rules-api</td>\n",
       "      <td>154.964787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/7/2024, 2:10:00.000 pm</td>\n",
       "      <td>u2-api</td>\n",
       "      <td>321.933312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp        ServiceName  avg_CounterValue\n",
       "0  12/7/2024, 2:10:00.000 pm  authorization-api        195.237478\n",
       "1  12/7/2024, 2:10:00.000 pm        payroll-api        166.074778\n",
       "2  12/7/2024, 2:10:00.000 pm         people-api        222.701978\n",
       "3  12/7/2024, 2:10:00.000 pm          rules-api        154.964787\n",
       "4  12/7/2024, 2:10:00.000 pm             u2-api        321.933312"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by timestamp, servicename, countername and average the values\n",
    "g_pc_df = f_pc_df.groupby(['timestamp', 'ServiceName']).max().reset_index()\n",
    "# concatenate servicename and countername to form a unique identifier\n",
    "# g_pc_df['ServiceCounter'] = g_pc_df['ServiceName'] + '_' + g_pc_df['CounterName']\n",
    "g_pc_df.drop(columns=['CounterName', 'InstanceId'], inplace=True)\n",
    "# pivot and add new columns for each countername\n",
    "# pc_df = pc_df.pivot(index=['timestamp'], columns='ServiceCounter', values='avg_CounterValue').reset_index()\n",
    "g_pc_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ServiceName</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>authorization-api</th>\n",
       "      <th>payroll-api</th>\n",
       "      <th>people-api</th>\n",
       "      <th>rules-api</th>\n",
       "      <th>u2-api</th>\n",
       "      <th>v4-api</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/7/2024, 2:10:00.000 pm</td>\n",
       "      <td>195.237478</td>\n",
       "      <td>166.074778</td>\n",
       "      <td>222.701978</td>\n",
       "      <td>154.964787</td>\n",
       "      <td>321.933312</td>\n",
       "      <td>188.207104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/7/2024, 2:15:00.000 pm</td>\n",
       "      <td>209.804493</td>\n",
       "      <td>168.015462</td>\n",
       "      <td>260.396646</td>\n",
       "      <td>160.246170</td>\n",
       "      <td>453.468979</td>\n",
       "      <td>243.386778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/7/2024, 2:20:00.000 pm</td>\n",
       "      <td>211.791053</td>\n",
       "      <td>168.011366</td>\n",
       "      <td>246.176154</td>\n",
       "      <td>159.637504</td>\n",
       "      <td>568.980275</td>\n",
       "      <td>320.584909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/7/2024, 2:25:00.000 pm</td>\n",
       "      <td>215.077683</td>\n",
       "      <td>170.391142</td>\n",
       "      <td>275.150438</td>\n",
       "      <td>164.397875</td>\n",
       "      <td>672.537805</td>\n",
       "      <td>357.249843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/7/2024, 2:30:00.000 pm</td>\n",
       "      <td>217.891635</td>\n",
       "      <td>175.484109</td>\n",
       "      <td>264.469709</td>\n",
       "      <td>176.117350</td>\n",
       "      <td>636.960768</td>\n",
       "      <td>340.284211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ServiceName                  timestamp  authorization-api  payroll-api  \\\n",
       "0            12/7/2024, 2:10:00.000 pm         195.237478   166.074778   \n",
       "1            12/7/2024, 2:15:00.000 pm         209.804493   168.015462   \n",
       "2            12/7/2024, 2:20:00.000 pm         211.791053   168.011366   \n",
       "3            12/7/2024, 2:25:00.000 pm         215.077683   170.391142   \n",
       "4            12/7/2024, 2:30:00.000 pm         217.891635   175.484109   \n",
       "\n",
       "ServiceName  people-api   rules-api      u2-api      v4-api  \n",
       "0            222.701978  154.964787  321.933312  188.207104  \n",
       "1            260.396646  160.246170  453.468979  243.386778  \n",
       "2            246.176154  159.637504  568.980275  320.584909  \n",
       "3            275.150438  164.397875  672.537805  357.249843  \n",
       "4            264.469709  176.117350  636.960768  340.284211  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcs = g_pc_df.pivot(index=['timestamp'], columns='ServiceName', values='avg_CounterValue').reset_index()\n",
    "pcs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import gcm\n",
    "from scipy.stats import halfnorm\n",
    "from dowhy.utils import plot, bar_plot\n",
    "\n",
    "causal_model = gcm.StructuralCausalModel(graph)\n",
    "for node in graph.nodes:\n",
    "    if len(list(graph.predecessors(node))) > 0:\n",
    "        # for all nodes with parents, we are using the linear regression model. \n",
    "        # in real world we need to use the appropriate model based on the data distribution.\n",
    "        causal_model.set_causal_mechanism(node, gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()))\n",
    "    else:\n",
    "        # for all nodes without parents, we are using the half normal distribution.\n",
    "        # in real world we need to use the appropriate model based on the data distribution.\n",
    "        causal_model.set_causal_mechanism(node, gcm.ScipyDistribution(halfnorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting causal mechanism of node v4-api: 100%|██████████| 6/6 [00:00<00:00, 214.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "gcm.fit(causal_model, pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating causal mechanisms...: 100%|██████████| 6/6 [00:00<00:00, 161.38it/s]\n",
      "Test permutations of given graph: 100%|██████████| 50/50 [00:00<00:00, 118.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalModelEvaluationResult(mechanism_performances={'v4-api': MechanismPerformanceResult(), 'rules-api': MechanismPerformanceResult(), 'payroll-api': MechanismPerformanceResult(), 'people-api': MechanismPerformanceResult(), 'authorization-api': MechanismPerformanceResult(), 'u2-api': MechanismPerformanceResult()}, pnl_assumptions={'rules-api': (1.0, False, 0.05), 'payroll-api': (1.0, False, 0.05), 'people-api': (1.0, False, 0.05), 'authorization-api': (1.0, False, 0.05), 'u2-api': (1.0, False, 0.05)}, graph_falsification=+-------------------------------------------------------------------------------------------------------+\n",
       "|                                         Falsificaton Summary                                          |\n",
       "+-------------------------------------------------------------------------------------------------------+\n",
       "| The given DAG is informative because 8 / 50 of the permutations lie in the Markov                     |\n",
       "| equivalence class of the given DAG (p-value: 0.16).                                                   |\n",
       "| The given DAG violates 1/16 LMCs and is better than 36.0% of the permuted DAGs (p-value: 0.64).       |\n",
       "| Based on the provided significance level (0.2) and because the DAG is informative,                    |\n",
       "| we reject the DAG.                                                                                    |\n",
       "+-------------------------------------------------------------------------------------------------------+, overall_kl_divergence=0.012877377059502787, plot_falsification_histogram=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcm.evaluate_causal_model(causal_model, pcs, compare_mechanism_baselines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
