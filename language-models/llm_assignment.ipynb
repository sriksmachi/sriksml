{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriksmachi/sriksml/blob/main/language-models/llm_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning FLAN T5\n",
        "\n",
        "This notebook contains code artifacts for fine tuning Flan-T5-small model. The notebook does the following tasks.\n",
        "\n",
        "1. Use a pre-trained google/flan-t5-small as the model.\n",
        "2. Verify if the summarization task works.\n",
        "3. Verify if the Q&A task works.\n",
        "4. Verify if English to French translation task works.\n",
        "5. Programmatically print the names of all the model layers and their dimensions.\n",
        "6. Programmatically print the total number of parameters/weights in this model.\n",
        "7. Set the tensor in final layer (decoder.final_layer_norm.weight) to all zeros.\n",
        "8. Verify if the Q&A task works aWer reseXng the weights of the above layer.\n",
        "9. Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and adjust all the dependent layers to match the dimension\n",
        "10. Reload the original google/flan-t5-small model.\n",
        "11. Train the model for a Q&A task that takes a context as additional input along with the queson. You can use SQuAD dataset. Choose an\n",
        "appropriate task prefix/trigger word and justify the choice.\n",
        "12. Evaluate the quality of the model\n",
        "\n",
        "Paper: https://arxiv.org/abs/2210.11416 </br>\n",
        "Official repo: https://github.com/google-research/t5x"
      ],
      "metadata": {
        "id": "2yMznrnobb3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "Q2vmIk-Mwfob"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install -q transformers[torch]\n",
        "pip install -q sentencepiece\n",
        "pip install -q datasets\n",
        "pip install -q tokenizers\n",
        "pip install -q evaluate\n",
        "pip install -q rouge_score\n",
        "pip install -q nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sDtFNLzJPNS"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "9ILlvvoyw2dA"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import torch\n",
        "from torch import nn\n",
        "import nltk\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
        "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from datasets import load_dataset\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "ScMqzLk2xit1"
      },
      "outputs": [],
      "source": [
        "from transformers.models.blip_2.modeling_blip_2 import AutoModelForSeq2SeqLM\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izzscG9kiQcN"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "xXrGklMChiWY"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import evaluate\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# loading Rouge\n",
        "rogue_metric = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsek27LtfCfu"
      },
      "source": [
        "## Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "DEA_hh5jxu-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66a3cf9-6a7e-489d-a43a-43594703dd07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "dataset = load_dataset(huggingface_dataset_name)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "nk9oB39Nxehc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a485c7-f70a-4a0f-8e42-c9c4b2d65621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 571,  405, 4505, 1635, 1707,  161,    3,   58,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "How does summarization work?</s>\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "sentence = \"How does summarization work ?\"\n",
        "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "print(sentence_encoded)\n",
        "sentence_decoded = tokenizer.decode(sentence_encoded[\"input_ids\"][0])\n",
        "print(sentence_decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "2NC1LRcez4aP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62005c0-6a2e-4f5b-f38c-2c68e7aaaec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue\n",
            "#Person1#: What an amazing film! I can't remember the last time I felt this good coming out of a movie theater!\n",
            "#Person2#: I know what you mean. Robert Redford is my favorite actor, so I knew I would like it.\n",
            "#Person1#: Yeah, but there were so many little things that were cool - the music, the lighting, the way the camera kept moving around... I don't think I've ever seen a more interesting film.\n",
            "#Person2#: It definitely got me thinking. Also, there was one pan in the middle that was pretty sad...\n",
            "#Person1#: Oh, don't remind me! I cried that whole time!\n",
            "#Person2#: Come on. Let's get some coffee and pie and keep talking!\n",
            "#Person1#: Great idea!\n",
            "==================================================\n",
            "Baseline Summary\n",
            "#Person1# and #Person2# discuss a movie they just finished. Both of them think it's amazing and interesting.\n",
            "==================================================\n",
            "Generated Summary without prompt\n",
            "I'm so glad I did!\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random_idx = random.randint(0, len(dataset[\"train\"]))\n",
        "print(\"Dialogue\")\n",
        "sentence = dataset[\"train\"][random_idx][\"dialogue\"]\n",
        "print(sentence)\n",
        "print(\"=====\"*10)\n",
        "print(\"Baseline Summary\")\n",
        "baseline_summary = dataset[\"train\"][random_idx][\"summary\"]\n",
        "print(baseline_summary)\n",
        "print(\"=====\"*10)\n",
        "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "pred_summary = model.generate(sentence_encoded['input_ids'], max_new_tokens=50)\n",
        "sentence_decoded = tokenizer.decode(pred_summary[0], skip_special_tokens=True)\n",
        "print(\"Generated Summary without prompt\")\n",
        "print(sentence_decoded)\n",
        "print(\"=====\"*10)\n",
        "rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_summary])\n",
        "print(rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "3TuHqtE51tYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66d0710-91e0-4bc2-b5ba-5711e85b49fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a sentence summarization bot. Please summarize the conversation.Dialogue:\n",
            "#Person1#: What an amazing film! I can't remember the last time I felt this good coming out of a movie theater!\n",
            "#Person2#: I know what you mean. Robert Redford is my favorite actor, so I knew I would like it.\n",
            "#Person1#: Yeah, but there were so many little things that were cool - the music, the lighting, the way the camera kept moving around... I don't think I've ever seen a more interesting film.\n",
            "#Person2#: It definitely got me thinking. Also, there was one pan in the middle that was pretty sad...\n",
            "#Person1#: Oh, don't remind me! I cried that whole time!\n",
            "#Person2#: Come on. Let's get some coffee and pie and keep talking!\n",
            "#Person1#: Great idea!.\n",
            "\n",
            "Generated Summary with prompt\n",
            "I'm so glad I did!\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"You are a sentence summarization bot. Please summarize the conversation.Dialogue:\\n{sentence}.\\n\"\n",
        "print(prompt)\n",
        "sentence_encoded = tokenizer(prompt, return_tensors='pt')\n",
        "pred_summary = model.generate(sentence_encoded['input_ids'],max_new_tokens=50)\n",
        "sentence_decoded = tokenizer.decode(pred_summary[0], skip_special_tokens=True)\n",
        "print(\"Generated Summary with prompt\")\n",
        "print(sentence_decoded)\n",
        "rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_summary])\n",
        "print(rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSAd_AW3fMSk"
      },
      "source": [
        "## Q & A Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "KCvbbf2GfO40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f22efe7-74fe-46a4-da72-27e36c8c2496"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 4000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ],
      "source": [
        "squad = load_dataset(\"squad\", split=\"train[:5000]\")\n",
        "squad = squad.train_test_split(test_size=0.2)\n",
        "squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "6TDcu0bLhBu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c3b5c8-18da-49a6-818f-04f873b962d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '56cfee5d234ae51400d9c0f7',\n",
              " 'title': 'Frédéric_Chopin',\n",
              " 'context': 'Chopin also endowed popular dance forms with a greater range of melody and expression. Chopin\\'s mazurkas, while originating in the traditional Polish dance (the mazurek), differed from the traditional variety in that they were written for the concert hall rather than the dance hall; \"it was Chopin who put the mazurka on the European musical map.\" The series of seven polonaises published in his lifetime (another nine were published posthumously), beginning with the Op. 26 pair (published 1836), set a new standard for music in the form. His waltzes were also written specifically for the salon recital rather than the ballroom and are frequently at rather faster tempos than their dance-floor equivalents.',\n",
              " 'question': 'How many polonaises were published while Chopin lived?',\n",
              " 'answers': {'text': ['seven'], 'answer_start': [363]}}"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ],
      "source": [
        "squad[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "QjcYS1sO7E_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48688255-d3f5-4ce4-ac08-5280b46ad986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "In 1827, soon after the death of Chopin's youngest sister Emilia, the family moved from the Warsaw University building, adjacent to the Kazimierz Palace, to lodgings just across the street from the university, in the south annex of the Krasiński Palace on Krakowskie Przedmieście,[n 5] where Chopin lived until he left Warsaw in 1830.[n 6] Here his parents continued running their boarding house for male students; the Chopin Family Parlour (Salonik Chopinów) became a museum in the 20th century. In 1829 the artist Ambroży Mieroszewski executed a set of portraits of Chopin family members, including the first known portrait of the composer.[n 7]\n",
            "==================================================\n",
            "Please answer a question about the following article about Frédéric_Chopin:\n",
            "\n",
            "In 1827, soon after the death of Chopin's youngest sister Emilia, the family moved from the Warsaw University building, adjacent to the Kazimierz Palace, to lodgings just across the street from the university, in the south annex of the Krasiński Palace on Krakowskie Przedmieście,[n 5] where Chopin lived until he left Warsaw in 1830.[n 6] Here his parents continued running their boarding house for male students; the Chopin Family Parlour (Salonik Chopinów) became a museum in the 20th century. In 1829 the artist Ambroży Mieroszewski executed a set of portraits of Chopin family members, including the first known portrait of the composer.[n 7]\n",
            "\n",
            "Was the Chopin family boarding house for male or female students?Was the Chopin family boarding house for male or female students?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "['male']\n",
            "==================================================\n",
            "tensor([[   0, 3955,  481,    1]])\n",
            "Generated Answer\n",
            "female students\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
          ]
        }
      ],
      "source": [
        "random_idx = random.randint(0, len(squad[\"train\"]))\n",
        "question = squad[\"train\"][random_idx][\"question\"]\n",
        "context = squad[\"train\"][random_idx][\"context\"]\n",
        "title = squad[\"train\"][random_idx][\"title\"]\n",
        "baseline_answer = squad[\"train\"][random_idx][\"answers\"]\n",
        "print(\"Context:\")\n",
        "print(context)\n",
        "print(\"=====\"*10)\n",
        "prompt = f\"Please answer a question about the following article about {title}:\\n\\n{context}\\n\\n{question}\"\n",
        "print(prompt + question)\n",
        "print(\"=====\"*10)\n",
        "print(\"Baseline answer:\")\n",
        "print(baseline_answer['text'])\n",
        "print(\"=====\"*10)\n",
        "sentence_encoded = tokenizer(prompt + question, return_tensors='pt', max_length=256, truncation=True)\n",
        "pred_answer = model.generate(sentence_encoded['input_ids'], max_new_tokens=100)\n",
        "print(pred_answer)\n",
        "sentence_decoded = tokenizer.decode(pred_answer[0], skip_special_tokens=True)\n",
        "print(\"Generated Answer\")\n",
        "print(sentence_decoded)\n",
        "print(\"=====\"*10)\n",
        "rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_answer['text']])\n",
        "print(rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRLyHHvIjWA2"
      },
      "source": [
        "## Language Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "JY9J0ZLmjXn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b434b9d-e127-460d-dc79-6f7d71b2d9fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the following sentence to french \n",
            " It is a wonderful day\n",
            "Predicted sentence: Il est un jour merveilleuse\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.3636363636363636,\n",
              " 'rouge2': 0.0,\n",
              " 'rougeL': 0.3636363636363636,\n",
              " 'rougeLsum': 0.3636363636363636}"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "prompt = \"Translate the following sentence to french \\n It is a wonderful day\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "print(prompt)\n",
        "translated = model.generate(inputs[\"input_ids\"], max_new_tokens=50)\n",
        "pred = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "print(f\"Predicted sentence: {pred}\")\n",
        "rogue_metric.compute(predictions=[pred], references=[\"C'est une journée merveilleuse\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yek3kIoOmBHU"
      },
      "source": [
        "## Describe the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "q-zAoKZPmD8e"
      },
      "outputs": [],
      "source": [
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "itcjeEeQxBQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1f5c22-41b4-4578-a08d-98b1c773488d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params: 76.96M\n",
            "Trainable params: 76.96M\n"
          ]
        }
      ],
      "source": [
        "def format_number_to_millions(number):\n",
        "  return f'{number / 1_000_000:.2f}M'\n",
        "\n",
        "def print_parameters_summary(model):\n",
        "  total_params = 0\n",
        "  trainable_params = 0\n",
        "  params = model.named_parameters()\n",
        "  for name, param in params:\n",
        "      if param.requires_grad:\n",
        "          trainable_params += param.numel()\n",
        "      total_params += param.numel()\n",
        "  return total_params, trainable_params\n",
        "\n",
        "total_params, trainable_params = print_parameters_summary(model)\n",
        "print(f'Total params: {format_number_to_millions(total_params)}')\n",
        "print(f'Trainable params: {format_number_to_millions(total_params)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "UU2fE_vIrjf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8cb0c3f2-2ab8-4fbd-bb2f-4c7e4fcee881"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        0       1\n",
              "shared.weight                                       32128   512.0\n",
              "encoder.block.0.layer.0.SelfAttention.q.weight        384   512.0\n",
              "encoder.block.0.layer.0.SelfAttention.k.weight        384   512.0\n",
              "encoder.block.0.layer.0.SelfAttention.v.weight        384   512.0\n",
              "encoder.block.0.layer.0.SelfAttention.o.weight        512   384.0\n",
              "...                                                   ...     ...\n",
              "decoder.block.7.layer.2.DenseReluDense.wi_1.weight   1024   512.0\n",
              "decoder.block.7.layer.2.DenseReluDense.wo.weight      512  1024.0\n",
              "decoder.block.7.layer.2.layer_norm.weight             512     NaN\n",
              "decoder.final_layer_norm.weight                       512     NaN\n",
              "lm_head.weight                                      32128   512.0\n",
              "\n",
              "[190 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28e3b7fb-9c6c-4994-9004-3e4d137c54ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>shared.weight</th>\n",
              "      <td>32128</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.q.weight</th>\n",
              "      <td>384</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.k.weight</th>\n",
              "      <td>384</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.v.weight</th>\n",
              "      <td>384</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.o.weight</th>\n",
              "      <td>512</td>\n",
              "      <td>384.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.block.7.layer.2.DenseReluDense.wi_1.weight</th>\n",
              "      <td>1024</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.block.7.layer.2.DenseReluDense.wo.weight</th>\n",
              "      <td>512</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.block.7.layer.2.layer_norm.weight</th>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.final_layer_norm.weight</th>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lm_head.weight</th>\n",
              "      <td>32128</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>190 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28e3b7fb-9c6c-4994-9004-3e4d137c54ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28e3b7fb-9c6c-4994-9004-3e4d137c54ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28e3b7fb-9c6c-4994-9004-3e4d137c54ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0a881de-eaa7-4bee-b7cf-164940a4dbbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0a881de-eaa7-4bee-b7cf-164940a4dbbe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0a881de-eaa7-4bee-b7cf-164940a4dbbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_360b8757-4b76-4d45-943e-c8fb3ff988a7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_360b8757-4b76-4d45-943e-c8fb3ff988a7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "dict = {}\n",
        "for name, param in model.named_parameters():\n",
        "  dict[name] = param.shape\n",
        "df = pd.DataFrame.from_dict(dict, orient='index')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7uhp1wxJ4b6"
      },
      "source": [
        "## Setting normalization weights to Zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "Cb4ecoQZmFk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03176bb8-3db4-440a-d9a5-1cb650f4e68a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "model.decoder.final_layer_norm.weight = nn.Parameter(torch.zeros(512))\n",
        "model.decoder.final_layer_norm.weight[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "_cp5bYcWoAiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1f04e6-987b-4cd0-f4c9-e4173cd159e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "The earthquake had a magnitude of 8.0 Ms and 7.9 Mw. The epicenter was in Wenchuan County, Ngawa Tibetan and Qiang Autonomous Prefecture, 80 km west/northwest of the provincial capital of Chengdu, with its main tremor occurring at 14:28:01.42 China Standard Time (06:28:01.42 UTC), on May 12, 2008 lasting for around 2 minutes, in the quake almost 80% of buildings were destroyed.\n",
            "==================================================\n",
            "given the context, answer the question in few sentences .\n",
            " context\n",
            " The earthquake had a magnitude of 8.0 Ms and 7.9 Mw. The epicenter was in Wenchuan County, Ngawa Tibetan and Qiang Autonomous Prefecture, 80 km west/northwest of the provincial capital of Chengdu, with its main tremor occurring at 14:28:01.42 China Standard Time (06:28:01.42 UTC), on May 12, 2008 lasting for around 2 minutes, in the quake almost 80% of buildings were destroyed. Question\n",
            " How long did the main tremor last?How long did the main tremor last?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "{'text': ['2 minutes'], 'answer_start': [317]}\n",
            "==================================================\n",
            "Generated Answer\n",
            "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
          ]
        }
      ],
      "source": [
        "random_idx = random.randint(0, len(squad[\"train\"]))\n",
        "question = squad[\"train\"][random_idx][\"question\"]\n",
        "context = squad[\"train\"][random_idx][\"context\"]\n",
        "baseline_answer = squad[\"train\"][random_idx][\"answers\"]\n",
        "print(\"Context:\")\n",
        "print(context)\n",
        "print(\"=====\"*10)\n",
        "prompt = f\"given the context, answer the question in few sentences .\\n context\\n {context} Question\\n {question}\"\n",
        "print(prompt + question)\n",
        "print(\"=====\"*10)\n",
        "print(\"Baseline answer:\")\n",
        "print(baseline_answer)\n",
        "print(\"=====\"*10)\n",
        "sentence_encoded = tokenizer(prompt + question, return_tensors='pt', max_length=256, truncation=True)\n",
        "pred_answer = model.generate(sentence_encoded['input_ids'], max_new_tokens=20)\n",
        "sentence_decoded = tokenizer.decode(pred_answer[0], skip_special_tokens=False)\n",
        "print(\"Generated Answer\")\n",
        "print(sentence_decoded)\n",
        "print(\"=====\"*10)\n",
        "rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_answer['text']])\n",
        "print(rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change layer dimensions"
      ],
      "metadata": {
        "id": "ScDLGxyKH2tL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "Gz0PxT1-LGY1"
      },
      "outputs": [],
      "source": [
        "# model.decoder.final_layer_norm.weight = nn.Parameter(torch.zeros(256))\n",
        "# model.lm_head.weight = nn.Parameter(torch.zeros(32128, 256))\n",
        "# for param in model.decoder.final_layer_norm.parameters():\n",
        "#   param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, d_model=256, ignore_mismatched_sizes=True)\n",
        "dict = {}\n",
        "for name, param in model.named_parameters():\n",
        "  dict[name] = param.shape\n",
        "df = pd.DataFrame.from_dict(dict, orient='index')\n",
        "df"
      ],
      "metadata": {
        "id": "LhPtE2lmK23W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "456514b2-e515-4c11-fd93-9420a8f59935"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-small and are newly initialized because the shapes did not match:\n",
            "- decoder.block.0.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.0.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.0.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.0.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.0.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.0.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.0.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.1.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.1.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.1.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.1.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.1.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.1.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.1.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.2.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.2.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.2.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.2.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.2.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.2.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.2.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.3.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.3.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.3.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.3.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.3.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.3.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.3.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.4.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.4.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.4.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.4.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.4.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.4.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.4.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.5.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.5.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.5.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.5.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.5.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.5.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.5.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.6.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.6.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.6.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.6.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.6.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.6.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.6.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.7.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.7.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.7.layer.1.EncDecAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- decoder.block.7.layer.1.EncDecAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.1.EncDecAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.block.7.layer.2.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.2.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- decoder.block.7.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- decoder.block.7.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- decoder.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.0.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.0.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.0.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.0.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.0.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.0.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.0.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.0.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.0.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.1.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.1.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.1.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.1.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.1.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.1.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.1.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.1.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.1.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.2.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.2.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.2.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.2.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.2.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.2.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.2.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.2.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.2.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.3.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.3.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.3.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.3.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.3.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.3.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.3.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.3.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.3.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.4.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.4.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.4.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.4.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.4.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.4.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.4.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.4.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.4.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.5.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.5.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.5.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.5.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.5.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.5.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.5.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.5.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.5.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.6.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.6.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.6.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.6.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.6.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.6.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.6.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.6.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.6.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.7.layer.0.SelfAttention.k.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.7.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([256, 384]) in the model instantiated\n",
            "- encoder.block.7.layer.0.SelfAttention.q.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.7.layer.0.SelfAttention.v.weight: found shape torch.Size([384, 512]) in the checkpoint and torch.Size([384, 256]) in the model instantiated\n",
            "- encoder.block.7.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.block.7.layer.1.DenseReluDense.wi_0.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.7.layer.1.DenseReluDense.wi_1.weight: found shape torch.Size([1024, 512]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
            "- encoder.block.7.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 1024]) in the model instantiated\n",
            "- encoder.block.7.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- encoder.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
            "- lm_head.weight: found shape torch.Size([32128, 512]) in the checkpoint and torch.Size([32128, 256]) in the model instantiated\n",
            "- shared.weight: found shape torch.Size([32128, 512]) in the checkpoint and torch.Size([32128, 256]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        0       1\n",
              "shared.weight                                       32128   256.0\n",
              "encoder.block.0.layer.0.SelfAttention.q.weight        384   256.0\n",
              "encoder.block.0.layer.0.SelfAttention.k.weight        384   256.0\n",
              "encoder.block.0.layer.0.SelfAttention.v.weight        384   256.0\n",
              "encoder.block.0.layer.0.SelfAttention.o.weight        256   384.0\n",
              "...                                                   ...     ...\n",
              "decoder.block.7.layer.2.DenseReluDense.wi_1.weight   1024   256.0\n",
              "decoder.block.7.layer.2.DenseReluDense.wo.weight      256  1024.0\n",
              "decoder.block.7.layer.2.layer_norm.weight             256     NaN\n",
              "decoder.final_layer_norm.weight                       256     NaN\n",
              "lm_head.weight                                      32128   256.0\n",
              "\n",
              "[190 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-277ddc90-72c2-4abd-b323-95996064b72e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>shared.weight</th>\n",
              "      <td>32128</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.q.weight</th>\n",
              "      <td>384</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.k.weight</th>\n",
              "      <td>384</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.v.weight</th>\n",
              "      <td>384</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encoder.block.0.layer.0.SelfAttention.o.weight</th>\n",
              "      <td>256</td>\n",
              "      <td>384.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.block.7.layer.2.DenseReluDense.wi_1.weight</th>\n",
              "      <td>1024</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.block.7.layer.2.DenseReluDense.wo.weight</th>\n",
              "      <td>256</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.block.7.layer.2.layer_norm.weight</th>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder.final_layer_norm.weight</th>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lm_head.weight</th>\n",
              "      <td>32128</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>190 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-277ddc90-72c2-4abd-b323-95996064b72e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-277ddc90-72c2-4abd-b323-95996064b72e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-277ddc90-72c2-4abd-b323-95996064b72e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11381ed7-0686-47ec-9d6c-335cedede28a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11381ed7-0686-47ec-9d6c-335cedede28a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11381ed7-0686-47ec-9d6c-335cedede28a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fbe3209f-d71f-4bff-9f86-07d025f57954\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbe3209f-d71f-4bff-9f86-07d025f57954 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_idx = random.randint(0, len(squad[\"train\"]))\n",
        "question = squad[\"train\"][random_idx][\"question\"]\n",
        "context = squad[\"train\"][random_idx][\"context\"]\n",
        "baseline_answer = squad[\"train\"][random_idx][\"answers\"]\n",
        "print(\"Context:\")\n",
        "print(context)\n",
        "print(\"=====\"*10)\n",
        "prompt = f\"given the context, answer the question in few sentences .\\n context\\n {context} Question\\n {question}\"\n",
        "print(prompt + question)\n",
        "print(\"=====\"*10)\n",
        "print(\"Baseline answer:\")\n",
        "print(baseline_answer)\n",
        "print(\"=====\"*10)\n",
        "sentence_encoded = tokenizer(prompt + question, return_tensors='pt', max_length=512, truncation=True)\n",
        "pred_answer = model.generate(sentence_encoded['input_ids'], max_new_tokens=20)\n",
        "sentence_decoded = tokenizer.decode(pred_answer[0], skip_special_tokens=False)\n",
        "print(\"Generated Answer\")\n",
        "print(sentence_decoded)\n",
        "print(\"=====\"*10)\n",
        "rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_answer['text']])\n",
        "print(rouge_score)"
      ],
      "metadata": {
        "id": "nAX9N4y2OeDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c89dbb4-d008-4de1-f668-0d6841caa1e4"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "Solar concentrating technologies such as parabolic dish, trough and Scheffler reflectors can provide process heat for commercial and industrial applications. The first commercial system was the Solar Total Energy Project (STEP) in Shenandoah, Georgia, USA where a field of 114 parabolic dishes provided 50% of the process heating, air conditioning and electrical requirements for a clothing factory. This grid-connected cogeneration system provided 400 kW of electricity plus thermal energy in the form of 401 kW steam and 468 kW chilled water, and had a one-hour peak load thermal storage. Evaporation ponds are shallow pools that concentrate dissolved solids through evaporation. The use of evaporation ponds to obtain salt from sea water is one of the oldest applications of solar energy. Modern uses include concentrating brine solutions used in leach mining and removing dissolved solids from waste streams. Clothes lines, clotheshorses, and clothes racks dry clothes through evaporation by wind and sunlight without consuming electricity or gas. In some states of the United States legislation protects the \"right to dry\" clothes. Unglazed transpired collectors (UTC) are perforated sun-facing walls used for preheating ventilation air. UTCs can raise the incoming air temperature up to 22 °C (40 °F) and deliver outlet temperatures of 45–60 °C (113–140 °F). The short payback period of transpired collectors (3 to 12 years) makes them a more cost-effective alternative than glazed collection systems. As of 2003, over 80 systems with a combined collector area of 35,000 square metres (380,000 sq ft) had been installed worldwide, including an 860 m2 (9,300 sq ft) collector in Costa Rica used for drying coffee beans and a 1,300 m2 (14,000 sq ft) collector in Coimbatore, India, used for drying marigolds.\n",
            "==================================================\n",
            "given the context, answer the question in few sentences .\n",
            " context\n",
            " Solar concentrating technologies such as parabolic dish, trough and Scheffler reflectors can provide process heat for commercial and industrial applications. The first commercial system was the Solar Total Energy Project (STEP) in Shenandoah, Georgia, USA where a field of 114 parabolic dishes provided 50% of the process heating, air conditioning and electrical requirements for a clothing factory. This grid-connected cogeneration system provided 400 kW of electricity plus thermal energy in the form of 401 kW steam and 468 kW chilled water, and had a one-hour peak load thermal storage. Evaporation ponds are shallow pools that concentrate dissolved solids through evaporation. The use of evaporation ponds to obtain salt from sea water is one of the oldest applications of solar energy. Modern uses include concentrating brine solutions used in leach mining and removing dissolved solids from waste streams. Clothes lines, clotheshorses, and clothes racks dry clothes through evaporation by wind and sunlight without consuming electricity or gas. In some states of the United States legislation protects the \"right to dry\" clothes. Unglazed transpired collectors (UTC) are perforated sun-facing walls used for preheating ventilation air. UTCs can raise the incoming air temperature up to 22 °C (40 °F) and deliver outlet temperatures of 45–60 °C (113–140 °F). The short payback period of transpired collectors (3 to 12 years) makes them a more cost-effective alternative than glazed collection systems. As of 2003, over 80 systems with a combined collector area of 35,000 square metres (380,000 sq ft) had been installed worldwide, including an 860 m2 (9,300 sq ft) collector in Costa Rica used for drying coffee beans and a 1,300 m2 (14,000 sq ft) collector in Coimbatore, India, used for drying marigolds. Question\n",
            " What are some items used to dry clothes without the use of electricity?What are some items used to dry clothes without the use of electricity?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "{'text': ['Clothes lines, clotheshorses, and clothes racks'], 'answer_start': [913]}\n",
            "==================================================\n",
            "Generated Answer\n",
            "<pad>atii vergessen ClaytonPläne Al<extra_id_82>ckel certified divine stalk SERVICES recolt measurement bekannt Environment fabricant fördern poems145ragged\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "cgI9vLLTKApe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/flan-t5-small\"\n",
        "flant5 = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "lH47N6RMI65B"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad = squad.flatten()\n",
        "squad"
      ],
      "metadata": {
        "id": "Sc3Zpb8HYV12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddbdaf9-2e7e-4cc9-c5ed-5d9f6f03ab0b"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers.text', 'answers.answer_start'],\n",
              "        num_rows: 4000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers.text', 'answers.answer_start'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squad['train'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHWEIS05EvRT",
        "outputId": "c17f1c2f-467a-48bb-b6d5-b530020bb441"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '56d4bd272ccc5a1400d831a0',\n",
              " 'title': 'Beyoncé',\n",
              " 'context': 'Her first acting role of 2006 was in the comedy film The Pink Panther starring opposite Steve Martin, grossing $158.8 million at the box office worldwide. Her second film Dreamgirls, the film version of the 1981 Broadway musical loosely based on The Supremes, received acclaim from critics and grossed $154 million internationally. In it, she starred opposite Jennifer Hudson, Jamie Foxx, and Eddie Murphy playing a pop singer based on Diana Ross. To promote the film, Beyoncé released \"Listen\" as the lead single from the soundtrack album. In April 2007, Beyoncé embarked on The Beyoncé Experience, her first worldwide concert tour, visiting 97 venues and grossed over $24 million.[note 1] Beyoncé conducted pre-concert food donation drives during six major stops in conjunction with her pastor at St. John\\'s and America\\'s Second Harvest. At the same time, B\\'Day was re-released with five additional songs, including her duet with Shakira \"Beautiful Liar\".',\n",
              " 'question': 'Which film did Beyoncé star with Steve Martin in?',\n",
              " 'answers.text': ['The Pink Panther'],\n",
              " 'answers.answer_start': [53]}"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** - The model does not work well if the answer is outside the context. Ideally we should eliminate all the data for which the answer does not lie within the context."
      ],
      "metadata": {
        "id": "KNU46sekjHjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_input_length = 1000\n",
        "squad = squad.filter(lambda x: (len(x.get('context')) + len(x.get('question')) < target_input_length) and (x.get('answers.answer_start')[0]) < target_input_length and len(x.get('answers.text')) > 0)\n",
        "squad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "7f60b79ac71748c6885aef33a5c7c2e6",
            "936d001ca14b40158123e745e9ffd01a",
            "b47b01e00f9047169d2a8b303f547248",
            "d8556f415bc74c778fdd73ea98623f6e",
            "c7532225e0344ed78a56edd34f9b560f",
            "d309b0d393a54158b275ef730c270523",
            "f833aff663514f28925c478c8360c226",
            "8a41d87ecf5a419f9d3036b60bbb1327",
            "c80e8e957bec4ec2b1ca59ee4f0f0fbc",
            "d6a7abf57cbb4eaf86441c7945a5169d",
            "45be42c23f7d40ca99107eea3f12afc8",
            "4fcc3da572304ad7b95d90167d04da06",
            "f46df58da6d84104a0d81f58fd01bf6e",
            "27509916b1f24243b49b3f7395d105e3",
            "55d309494ca94087b6cf475d6e34fb6f",
            "9c5492a2ead947768a4098f0e6355ad9",
            "cad73fc9ee8d4134ae26ee874b46230c",
            "75aa0717d9774e488067b4e730af0e0f",
            "4d2d65666b4e4fae9f74d4080d6e7bf0",
            "9fc1eed4a09848da9db327f12c12e1fe",
            "fefdccab9fb64b369a080c89ec65f335",
            "f7d290c1ac194e158b2aaa1d7736dcfb"
          ]
        },
        "id": "N1104pU6f8sY",
        "outputId": "75e63195-a05c-475c-a86e-4b4110c416d1"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/3027 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f60b79ac71748c6885aef33a5c7c2e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/749 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fcc3da572304ad7b95d90167d04da06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers.text', 'answers.answer_start'],\n",
              "        num_rows: 3027\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers.text', 'answers.answer_start'],\n",
              "        num_rows: 749\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "lengths = [len(row['context'] + row['question']) for row in squad['train']]\n",
        "plt.hist(lengths, bins=100)\n",
        "plt.show()\n",
        "target_max_length = int(np.percentile(lengths, 80))\n",
        "print(f\"Max length: {target_max_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "URuRGM33beYa",
        "outputId": "970cf768-f137-4648-8d46-3ad1e6e5a7a0"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length: 855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Justification for prompt\n",
        "\n",
        "The prompts are collected from Flan 2022 Collection (Chung et al, arXiv:2210.11416).\n",
        "\n",
        "Ref: https://arxiv.org/abs/2301.13688\n",
        "Prompts are selected from this github https://github.com/google-research/FLAN/blob/main/flan/v2/flan_templates_branched.py\n",
        "\n"
      ],
      "metadata": {
        "id": "HIv9JgEMfk7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(examples):\n",
        "  \"\"\"Adds prefix, tokenizes and sets the labels\"\"\"\n",
        "  questions = examples[\"question\"]\n",
        "  contexts = examples[\"context\"]\n",
        "  titles = examples[\"title\"]\n",
        "  answers = []\n",
        "  for answer in examples[\"answers.text\"]:\n",
        "    answers.append(answer[0])\n",
        "  inputs = []\n",
        "  for question, context in zip(questions, contexts):\n",
        "    prefix = f\"\"\"Answer a question about this article:\\n{context}\\nQ:{question}A:\"\"\"\n",
        "    input = prefix.format(context=context.strip(), question=question.strip())\n",
        "    inputs.append(input)\n",
        "  model_inputs = tokenizer(inputs,\n",
        "                           truncation=True,\n",
        "                           padding=\"max_length\",\n",
        "                           return_tensors='pt',\n",
        "                           max_length=target_max_length)\n",
        "  labels = tokenizer(text_target=answers, max_length=target_max_length, truncation=True)\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs\n",
        "\n",
        "tensored_data = squad.map(preprocess_data, remove_columns=squad[\"train\"].column_names, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "03a9f25c8eea4d1aa854d47e9c8fc9aa",
            "457e754581ef4da18c17f0ed42177f69",
            "c41b39da13b84a8bbcca45e76709d85b",
            "be31edcb38814638b5b54c2e6cb36001",
            "6bda9046359b4d6287c543168f131dd1",
            "2187c218cab442d4a6bd77e7c2f0961b",
            "0d23b25ddf5c48d981a1c2ffee627b56",
            "0909e702df1449d0b68d7d47e9e079af",
            "02d4a56746fc4003903cedee7e7f3bd9",
            "2f8cde2266c94b0f9698e1da006c83f8",
            "202a9483099d424e9c069f0edca7f894",
            "11d507ad30c74f039ff48f8ec51d015a",
            "dbbeb7b9b19840bc8f1f9f4bec568cf2",
            "d253af9474174c3c993b5f7f6c4cd8d8",
            "3c68f615d0fa4680a738d91b36775a06",
            "0a6990b0323947ce893f3c7fd182be8b",
            "a4d6932ac6ef4aa9b6fc5f3e117236cd",
            "5ebc2c368437442185c535b1512f665d",
            "d2fbf6790d73418bbabc19eeefe7ebc7",
            "9ab9b1d0ccba4a55a0a5f5e0ca01f477",
            "39365c4792e848f4be1b274a34b7b3fc",
            "6b65c34246ff4ea4b8ef88e5a741ee4b"
          ]
        },
        "id": "qYP18t99LHZW",
        "outputId": "dd187c9d-cfd5-454e-de36-c5b0db440845"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3027 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03a9f25c8eea4d1aa854d47e9c8fc9aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/749 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11d507ad30c74f039ff48f8ec51d015a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensored_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C7ju0QUacQf",
        "outputId": "48baf21a-e601-4f01-9a6b-87b8864bc5bf"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3027\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 749\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tensored_data[\"train\"][0][\"input_ids\"], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "hC7o_7OH71W6",
        "outputId": "459d0516-4c12-4ee9-e890-87587e27f908"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer a question about this article: The novel is renowned for its warmth and humor, despite dealing with the serious issues of rape and racial inequality. The narrator\\'s father, Atticus Finch, has served as a moral hero for many readers and as a model of integrity for lawyers. One critic explains the novel\\'s impact by writing, \"In the twentieth century, To Kill a Mockingbird is probably the most widely read book dealing with race in America, and its protagonist, Atticus Finch, the most enduring fictional image of racial heroism.\" Q:Who is the protagonist of the novel?A:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tensored_data[\"train\"][0][\"labels\"], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "91bczBLiBDHO",
        "outputId": "51eeee8b-5ec9-4d43-9820-3627e571bfcc"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Atticus Finch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tensored_data[\"train\"][500][\"input_ids\"], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "k4iQpery8Pho",
        "outputId": "a859a0bf-72c0-4f79-c889-fe871291231e"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Answer a question about this article: The official position of the Ministry of Foreign Affairs of the People's Republic of China is that the Ming implemented a policy of managing Tibet according to conventions and customs, granting titles and setting up administrative organs over Tibet. The State Council Information Office of the People's Republic states that the Ming dynasty's Ü-Tsang Commanding Office governed most areas of Tibet. It also states that while the Ming abolished the policy council set up by the Mongol Yuan to manage local affairs in Tibet and the Mongol system of Imperial Tutors to govern religious affairs, the Ming adopted a policy of bestowing titles upon religious leaders who had submitted to the Ming dynasty. For example, an edict of the Hongwu Emperor in 1373 appointed the Tibetan leader Choskunskyabs as the General of the Ngari Military and Civil Wanhu Office, stating: Q:Who governed most areas of Tibet?A:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tensored_data[\"train\"][500][\"labels\"], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "p_CA9qfrBHld",
        "outputId": "d5473af5-6fdd-4ffb-ec81-b111f860e61f"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ming dynasty's Ü-Tsang Commanding Office\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
      ],
      "metadata": {
        "id": "89nac0KlIFZE"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Parameters\n",
        "L_RATE = 5e-5\n",
        "BATCH_SIZE = 8\n",
        "PER_DEVICE_EVAL_BATCH = 8\n",
        "WEIGHT_DECAY = 0.01\n",
        "SAVE_TOTAL_LIM = 3\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "   preds, labels = eval_preds\n",
        "   # decode preds and labels\n",
        "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "   # rougeLSum expects newline after each sentence\n",
        "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "   result = rogue_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "   return result\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "   output_dir=\"./results\",\n",
        "   evaluation_strategy=\"epoch\",\n",
        "   learning_rate=L_RATE,\n",
        "   per_device_train_batch_size=BATCH_SIZE,\n",
        "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
        "   weight_decay=WEIGHT_DECAY,\n",
        "   save_total_limit=SAVE_TOTAL_LIM,\n",
        "   num_train_epochs=NUM_EPOCHS,\n",
        "   predict_with_generate=True,\n",
        "   push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "id": "zkuXMQM4LOW3"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tensored_data[\"train\"],\n",
        "   eval_dataset=tensored_data[\"test\"],\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "8AG2Q42O-D66"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with 5k rows in data, training time on T4 -> 10 min\n",
        "# Complete dataset, 10 epochs -> 1-2 hours\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rkTIxBrFIUm4",
        "outputId": "6a2d0dea-b713-431e-bce6-644f8b03c952"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1137' max='1137' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1137/1137 09:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>23.304234</td>\n",
              "      <td>0.006620</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006592</td>\n",
              "      <td>0.006585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>28.312100</td>\n",
              "      <td>24.046284</td>\n",
              "      <td>0.008870</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.008838</td>\n",
              "      <td>0.008901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>26.961200</td>\n",
              "      <td>23.082314</td>\n",
              "      <td>0.010581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010328</td>\n",
              "      <td>0.010369</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1137, training_loss=27.511879363181617, metrics={'train_runtime': 575.9612, 'train_samples_per_second': 15.767, 'train_steps_per_second': 1.974, 'total_flos': 1409473906836480.0, 'train_loss': 27.511879363181617, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "XUChNTfxOXA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "57dMjqjrdxW3",
        "outputId": "b015cfce-147b-45a0-bdd9-9de42024fa93"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [94/94 00:41]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 23.082313537597656,\n",
              " 'eval_rouge1': 0.010580581708752602,\n",
              " 'eval_rouge2': 0.0,\n",
              " 'eval_rougeL': 0.010328489934631459,\n",
              " 'eval_rougeLsum': 0.010369333233151657,\n",
              " 'eval_runtime': 42.4463,\n",
              " 'eval_samples_per_second': 17.646,\n",
              " 'eval_steps_per_second': 2.215,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_checkpoint = \"./results/checkpoint-500\"\n",
        "finetuned_model = T5ForConditionalGeneration.from_pretrained(last_checkpoint)\n",
        "tokenizer = T5Tokenizer.from_pretrained(last_checkpoint)"
      ],
      "metadata": {
        "id": "mgvyIMn-OYYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0c9c84-2caf-4353-aa94-e3ec22218b9c"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"What do you think about the benefit of Artificial Intelligence?\"\n",
        "inputs = \"Please answer to this question: \" + my_question\n",
        "inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
        "outputs = finetuned_model.generate(**inputs)\n",
        "print(outputs[0])\n",
        "answer = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JWtkW1QOlGw",
        "outputId": "27d9c80a-098b-408e-c9db-aad52e6aaf5c"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 3, 9, 1])\n",
            "<pad> a</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  random_idx = random.randint(0, len(squad[\"train\"]))\n",
        "  question = squad[\"train\"][random_idx][\"question\"]\n",
        "  context = squad[\"train\"][random_idx][\"context\"]\n",
        "  title = squad[\"train\"][random_idx][\"title\"]\n",
        "  baseline_answer = squad[\"train\"][random_idx][\"answers.text\"]\n",
        "  prompt = f\"\"\"Please answer a question about the following article about {title}\\n{context}\\n\\nQ: {question}\"\"\"\n",
        "  print(prompt)\n",
        "  print(\"=====\"*10)\n",
        "  print(\"Baseline answer:\")\n",
        "  print(baseline_answer)\n",
        "  print(\"=====\"*10)\n",
        "  sentence_encoded = tokenizer(prompt, return_tensors='pt', max_length=256, truncation=True)\n",
        "  pred_answer = finetuned_model.generate(sentence_encoded['input_ids'], max_new_tokens=100)\n",
        "  sentence_decoded = tokenizer.decode(pred_answer[0], skip_special_tokens=True)\n",
        "  print(\"Generated Answer\")\n",
        "  print(sentence_decoded)\n",
        "  print(\"=====\"*10)\n",
        "  rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_answer])\n",
        "  print(rouge_score)\n",
        "  print(\"#####\"*20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ysM-75TOtdA",
        "outputId": "d70c141e-524a-4c80-8275-342f4217e6d1"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please answer a question about the following article about To_Kill_a_Mockingbird\n",
            "One year after its publication To Kill a Mockingbird had been translated into ten languages. In the years since, it has sold more than 30 million copies and been translated into more than 40 languages. The novel has never been out of print in hardcover or paperback, and has become part of the standard literature curriculum. A 2008 survey of secondary books read by students between grades 9–12 in the U.S. indicates the novel is the most widely read book in these grades. A 1991 survey by the Book of the Month Club and the Library of Congress Center for the Book found that To Kill a Mockingbird was rated behind only the Bible in books that are \"most often cited as making a difference\".[note 1] It is considered by some to be the Great American Novel.\n",
            "\n",
            "Q: After one year when To Kill a Mockingbird first came out, how many languages has it been printed in?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "['ten']\n",
            "==================================================\n",
            "Generated Answer\n",
            "a\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "####################################################################################################\n",
            "Please answer a question about the following article about Frédéric_Chopin\n",
            "Chopin's life was covered in a BBC TV documentary Chopin – The Women Behind The Music (2010), and in a 2010 documentary realised by Angelo Bozzolini and Roberto Prosseda for Italian television.\n",
            "\n",
            "Q: What two people created a documentary on Chopin for Italian tv?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "['Angelo Bozzolini and Roberto Prosseda']\n",
            "==================================================\n",
            "Generated Answer\n",
            "a\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "####################################################################################################\n",
            "Please answer a question about the following article about 2008_Sichuan_earthquake\n",
            "The 2008 Sichuan earthquake or the Great Sichuan earthquake, measured at 8.0 Ms and 7.9 Mw, and occurred at 02:28:01 PM China Standard Time at epicenter (06:28:01 UTC) on May 12 in Sichuan province, killed 69,197 people and left 18,222 missing.\n",
            "\n",
            "Q: What day did the earthquake occur?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "['May 12']\n",
            "==================================================\n",
            "Generated Answer\n",
            "a\n",
            "==================================================\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "####################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix"
      ],
      "metadata": {
        "id": "5IgsaMBre3mw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply PEFT\n",
        "\n",
        "Parameter efficient fine tuning is an approach towards fine tuning large language models that fine tunes the model without altering all the model weights. You can learn more about it from my block post [here](https://www.linkedin.com/pulse/finetuning-large-language-models-using-novel-peft-srikanth-machiraju-owe2c%3FtrackingId=AVwu8o6uR%252F6J3n0BB6U7IA%253D%253D/?trackingId=AVwu8o6uR%2F6J3n0BB6U7IA%3D%3D)"
      ],
      "metadata": {
        "id": "OdMJsPK0MvtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install -q peft"
      ],
      "metadata": {
        "id": "E_50npF7T1IV"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4gK4PCEaV1Z",
        "outputId": "a17e009d-4545-4f90-f21a-3c89ae43d575"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5ForConditionalGeneration(\n",
            "  (shared): Embedding(32128, 512)\n",
            "  (encoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 6)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-7): 7 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 6)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-7): 7 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
        "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16, #Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"lm_head\"], # we can use layer names from above to target more modules, here I'm only training linear layer\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "peft_model.print_trainable_parameters()\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "   model=peft_model,\n",
        "   args=training_args,\n",
        "   train_dataset=tensored_data[\"train\"],\n",
        "   eval_dataset=tensored_data[\"test\"],\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-hS-iOYMzb9",
        "outputId": "9ecfd12f-6f3f-4a42-a4c8-84ffd919410d"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 522,240 || all params: 77,483,392 || trainable%: 0.6740025010779084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vb4Or4bNYE3x",
        "outputId": "51526c06-d813-4007-b334-7dca034d3957"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1137' max='1137' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1137/1137 06:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.305400</td>\n",
              "      <td>0.827916</td>\n",
              "      <td>0.523381</td>\n",
              "      <td>0.827761</td>\n",
              "      <td>0.827597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.565700</td>\n",
              "      <td>0.303915</td>\n",
              "      <td>0.827446</td>\n",
              "      <td>0.522079</td>\n",
              "      <td>0.827243</td>\n",
              "      <td>0.827721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>0.303395</td>\n",
              "      <td>0.826331</td>\n",
              "      <td>0.520538</td>\n",
              "      <td>0.826208</td>\n",
              "      <td>0.826463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1137, training_loss=0.558643129696003, metrics={'train_runtime': 396.8294, 'train_samples_per_second': 22.884, 'train_steps_per_second': 2.865, 'total_flos': 2843276640860160.0, 'train_loss': 0.558643129696003, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  random_idx = random.randint(0, len(squad[\"train\"]))\n",
        "  question = squad[\"train\"][random_idx][\"question\"]\n",
        "  context = squad[\"train\"][random_idx][\"context\"]\n",
        "  title = squad[\"train\"][random_idx][\"title\"]\n",
        "  baseline_answer = squad[\"train\"][random_idx][\"answers.text\"]\n",
        "  prompt = f\"\"\"Please answer a question about the following article about {title}\\n{context}\\n\\nQ: {question}\"\"\"\n",
        "  print(prompt)\n",
        "  print(\"=====\"*10)\n",
        "  print(\"Baseline answer:\")\n",
        "  print(baseline_answer)\n",
        "  print(\"=====\"*10)\n",
        "  sentence_encoded = tokenizer(prompt, return_tensors='pt', max_length=256, truncation=True)\n",
        "  pred_answer = peft_model.generate(input_ids=sentence_encoded['input_ids'])\n",
        "  sentence_decoded = tokenizer.decode(pred_answer[0], skip_special_tokens=True)\n",
        "  print(\"Generated Answer\")\n",
        "  print(sentence_decoded)\n",
        "  print(\"=====\"*10)\n",
        "  rouge_score = rogue_metric.compute(predictions=[sentence_decoded], references=[baseline_answer])\n",
        "  print(rouge_score)\n",
        "  print(\"#####\"*20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "KvUmpDMwvPLi",
        "outputId": "2626dc56-983e-4a9e-faf5-a425ccbee172"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please answer a question about the following article about New_York_City\n",
            "New York City has over 28,000 acres (110 km2) of municipal parkland and 14 miles (23 km) of public beaches. Parks in New York City include Central Park, Prospect Park, Flushing Meadows–Corona Park, Forest Park, and Washington Square Park. The largest municipal park in the city is Pelham Bay Park with 2,700 acres (1,093 ha).\n",
            "\n",
            "Q: What is the biggest public park in the city?\n",
            "==================================================\n",
            "Baseline answer:\n",
            "['Pelham Bay Park']\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-269-f40fe4cf07c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0msentence_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mpred_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeft_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0msentence_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_answer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated Answer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prompt_learning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1549\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to initialize the model with valid token embeddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuning using Human feedback\n",
        "\n",
        "[WIP]"
      ],
      "metadata": {
        "id": "jsDn1QXOMz-i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpZOxBCre5-e"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZTkX3mJsC5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYO2k46fIfpI3xEYyUK1fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f60b79ac71748c6885aef33a5c7c2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_936d001ca14b40158123e745e9ffd01a",
              "IPY_MODEL_b47b01e00f9047169d2a8b303f547248",
              "IPY_MODEL_d8556f415bc74c778fdd73ea98623f6e"
            ],
            "layout": "IPY_MODEL_c7532225e0344ed78a56edd34f9b560f"
          }
        },
        "936d001ca14b40158123e745e9ffd01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d309b0d393a54158b275ef730c270523",
            "placeholder": "​",
            "style": "IPY_MODEL_f833aff663514f28925c478c8360c226",
            "value": "Filter: 100%"
          }
        },
        "b47b01e00f9047169d2a8b303f547248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a41d87ecf5a419f9d3036b60bbb1327",
            "max": 3027,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c80e8e957bec4ec2b1ca59ee4f0f0fbc",
            "value": 3027
          }
        },
        "d8556f415bc74c778fdd73ea98623f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a7abf57cbb4eaf86441c7945a5169d",
            "placeholder": "​",
            "style": "IPY_MODEL_45be42c23f7d40ca99107eea3f12afc8",
            "value": " 3027/3027 [00:00&lt;00:00, 28568.25 examples/s]"
          }
        },
        "c7532225e0344ed78a56edd34f9b560f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d309b0d393a54158b275ef730c270523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f833aff663514f28925c478c8360c226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a41d87ecf5a419f9d3036b60bbb1327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80e8e957bec4ec2b1ca59ee4f0f0fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6a7abf57cbb4eaf86441c7945a5169d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45be42c23f7d40ca99107eea3f12afc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fcc3da572304ad7b95d90167d04da06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f46df58da6d84104a0d81f58fd01bf6e",
              "IPY_MODEL_27509916b1f24243b49b3f7395d105e3",
              "IPY_MODEL_55d309494ca94087b6cf475d6e34fb6f"
            ],
            "layout": "IPY_MODEL_9c5492a2ead947768a4098f0e6355ad9"
          }
        },
        "f46df58da6d84104a0d81f58fd01bf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad73fc9ee8d4134ae26ee874b46230c",
            "placeholder": "​",
            "style": "IPY_MODEL_75aa0717d9774e488067b4e730af0e0f",
            "value": "Filter: 100%"
          }
        },
        "27509916b1f24243b49b3f7395d105e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2d65666b4e4fae9f74d4080d6e7bf0",
            "max": 749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fc1eed4a09848da9db327f12c12e1fe",
            "value": 749
          }
        },
        "55d309494ca94087b6cf475d6e34fb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fefdccab9fb64b369a080c89ec65f335",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d290c1ac194e158b2aaa1d7736dcfb",
            "value": " 749/749 [00:00&lt;00:00, 16928.65 examples/s]"
          }
        },
        "9c5492a2ead947768a4098f0e6355ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad73fc9ee8d4134ae26ee874b46230c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75aa0717d9774e488067b4e730af0e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d2d65666b4e4fae9f74d4080d6e7bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc1eed4a09848da9db327f12c12e1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fefdccab9fb64b369a080c89ec65f335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d290c1ac194e158b2aaa1d7736dcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03a9f25c8eea4d1aa854d47e9c8fc9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_457e754581ef4da18c17f0ed42177f69",
              "IPY_MODEL_c41b39da13b84a8bbcca45e76709d85b",
              "IPY_MODEL_be31edcb38814638b5b54c2e6cb36001"
            ],
            "layout": "IPY_MODEL_6bda9046359b4d6287c543168f131dd1"
          }
        },
        "457e754581ef4da18c17f0ed42177f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2187c218cab442d4a6bd77e7c2f0961b",
            "placeholder": "​",
            "style": "IPY_MODEL_0d23b25ddf5c48d981a1c2ffee627b56",
            "value": "Map: 100%"
          }
        },
        "c41b39da13b84a8bbcca45e76709d85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0909e702df1449d0b68d7d47e9e079af",
            "max": 3027,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02d4a56746fc4003903cedee7e7f3bd9",
            "value": 3027
          }
        },
        "be31edcb38814638b5b54c2e6cb36001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f8cde2266c94b0f9698e1da006c83f8",
            "placeholder": "​",
            "style": "IPY_MODEL_202a9483099d424e9c069f0edca7f894",
            "value": " 3027/3027 [00:00&lt;00:00, 3992.91 examples/s]"
          }
        },
        "6bda9046359b4d6287c543168f131dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2187c218cab442d4a6bd77e7c2f0961b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d23b25ddf5c48d981a1c2ffee627b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0909e702df1449d0b68d7d47e9e079af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d4a56746fc4003903cedee7e7f3bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f8cde2266c94b0f9698e1da006c83f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202a9483099d424e9c069f0edca7f894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11d507ad30c74f039ff48f8ec51d015a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbbeb7b9b19840bc8f1f9f4bec568cf2",
              "IPY_MODEL_d253af9474174c3c993b5f7f6c4cd8d8",
              "IPY_MODEL_3c68f615d0fa4680a738d91b36775a06"
            ],
            "layout": "IPY_MODEL_0a6990b0323947ce893f3c7fd182be8b"
          }
        },
        "dbbeb7b9b19840bc8f1f9f4bec568cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d6932ac6ef4aa9b6fc5f3e117236cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5ebc2c368437442185c535b1512f665d",
            "value": "Map: 100%"
          }
        },
        "d253af9474174c3c993b5f7f6c4cd8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fbf6790d73418bbabc19eeefe7ebc7",
            "max": 749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ab9b1d0ccba4a55a0a5f5e0ca01f477",
            "value": 749
          }
        },
        "3c68f615d0fa4680a738d91b36775a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39365c4792e848f4be1b274a34b7b3fc",
            "placeholder": "​",
            "style": "IPY_MODEL_6b65c34246ff4ea4b8ef88e5a741ee4b",
            "value": " 749/749 [00:00&lt;00:00, 3748.95 examples/s]"
          }
        },
        "0a6990b0323947ce893f3c7fd182be8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d6932ac6ef4aa9b6fc5f3e117236cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebc2c368437442185c535b1512f665d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2fbf6790d73418bbabc19eeefe7ebc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab9b1d0ccba4a55a0a5f5e0ca01f477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39365c4792e848f4be1b274a34b7b3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b65c34246ff4ea4b8ef88e5a741ee4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}