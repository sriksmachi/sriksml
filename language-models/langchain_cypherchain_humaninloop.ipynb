{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install langchain langchain_community\n",
    "# %pip install neo4j\n",
    "# %pip install langchain_openai\n",
    "# %pip install python-dotenv\n",
    "# %pip install chromadb\n",
    "# %pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEO4J_URI'] = 'bolt://localhost:7690'\n",
    "os.environ['NEO4J_USERNAME'] = 'neo4j'\n",
    "os.environ['NEO4J_PASSWORD'] = 'Password@123'\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://sriks-openai.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-05-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"] = \"gpt-4o\"\n",
    "os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"] = \"text-embedding-ada-002\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"],\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What is the root cause request id 8ff8696695aa73588ac454809741e2ea\",\n",
    "        \"query\": \"MATCH (n)-[r:DEPENDS_ON]->(m) where n.id <> 'ROOT' OR m.id <> 'ROOT' and r.operationId = 8ff8696695aa73588ac454809741e2ea RETURN n.id, r.duration, r.operation_Name, m.id ORDER BY r.duration DESC LIMIT 3\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"what is the longest running operation\",\n",
    "        \"query\": \"MATCH (n)-[r:DEPENDS_ON]->(m) where n.id <> 'ROOT' OR m.id <> 'ROOT' RETURN n.id, r.duration, r.operation_Name, m.id ORDER BY r.duration DESC LIMIT 3\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector, MaxMarginalRelevanceExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.graph_qa.cypher import construct_schema\n",
    "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "# load human intervention tools\n",
    "tools = load_tools(\n",
    "    [\"human\"], llm\n",
    ")\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "\n",
    "EXAMPLES_PROMPT_TEMPLATE = \"\"\"   \n",
    "                Input: {question},\n",
    "                Output: {query}\n",
    "            \"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"query\"], template=EXAMPLES_PROMPT_TEMPLATE)\n",
    "\n",
    "cypherPromptTemplate = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to answer questions.\n",
    "Convert the user's question based on the schema.\n",
    "Instructions: Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "Important: In the generated Cypher query, the RETURN statement must explicitly include the property values used in the query's filtering condition, alongside the main information requested from the original question.\n",
    "\n",
    "Question: {question}\n",
    "input:\n",
    "\"\"\"\n",
    "\n",
    "similaritySelector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples=examples, \n",
    "    embeddings=embeddings, \n",
    "    k=1,\n",
    "    vectorstore_cls=Chroma\n",
    ")\n",
    "\n",
    "cypherPrompt = FewShotPromptTemplate(\n",
    "    example_selector=similaritySelector,\n",
    "    example_prompt=example_prompt,\n",
    "    input_variables=[\"question\", \"schema\"], \n",
    "    prefix=cypherPromptTemplate,\n",
    "    suffix=\"the question is:{question}\",\n",
    ")\n",
    "\n",
    "cypherqachain = GraphCypherQAChain.from_llm(\n",
    "    llm = llm,\n",
    "    return_intermediate_steps=True,\n",
    "    validate_cypher=True,\n",
    "    graph=graph, \n",
    "    verbose=True,\n",
    "    k=3,\n",
    "    use_function_response=True,\n",
    "    cypherPrompt=cypherPrompt,\n",
    "    return_direct=True,\n",
    "    output_key=\"input\",\n",
    ") \n",
    "\n",
    "schema  = construct_schema(graph.get_structured_schema, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (crn:cloudRoleName)-[r:AZURE_DEPENDS_ON]->(sql:SQL)\n",
      "RETURN crn.id, COUNT(r) AS azureDependencyCount\n",
      "ORDER BY azureDependencyCount DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'which nodes has max azure dependencies',\n",
       " 'input': [{'crn.id': 'people-api', 'azureDependencyCount': 23}],\n",
       " 'intermediate_steps': [{'query': 'cypher\\nMATCH (crn:cloudRoleName)-[r:AZURE_DEPENDS_ON]->(sql:SQL)\\nRETURN crn.id, COUNT(r) AS azureDependencyCount\\nORDER BY azureDependencyCount DESC\\nLIMIT 1\\n'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cypher chain invocation\n",
    "cypherqachain.invoke({\"query\": \"which nodes has max azure dependencies\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code, creates a confidence chain that will be used to ask LLM how confident it is query generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_prompt_template = \"\"\"Given the {input}, {schema} and the question from user question:{question} how confident are you in the query on scale of 1-5, answer precisely in JSON format\n",
    "score: 1, reason: The query is not clear, assumptions: The query is not clear\"\"\"\n",
    "\n",
    "confidence_prompt = PromptTemplate(template=confidence_prompt_template, input_variables=[\"input\", \"schema\"])\n",
    "\n",
    "# ask llm on confidence of the query\n",
    "confidenceChain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=confidence_prompt\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_interaction_prompt = \"\"\"How do you want to proceed?\"\"\"\n",
    "agent = initialize_agent(\n",
    "    tools=tools, \n",
    "    llm=llm, \n",
    "    agent=\"zero-shot-react-description\", \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True,\n",
    "    prompt=human_interaction_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QA_GENERATION_TEMPLATE = \"\"\"\n",
    "       Task: answer the question you are given based on the context provided.\n",
    "       Instructions:\n",
    "        You are an assistant that helps to form nice and human understandable answers. \n",
    "        Use the context information provided to generate a well organized and comprehensve answer to the user's question. \n",
    "        When the provided information contains multiple elements, structure your answer as a bulleted or numbered list to enhance clarity and readability.\n",
    "        You must use the information to construct your answer. \n",
    "        The provided information is authoritative; do not doubt it or try to use your internal knowledge to correct it. \n",
    "        Make the answer sound like a response to the question without mentioning that you based the result on the given information. \n",
    "        If there is no information provided, say that the knowledge base returned empty results.\n",
    "\n",
    "        Here's the information:\n",
    "        {context}\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \n",
    "        Also explain the assumptions you made while generating the answer given the query used to generate the context and the schema provided.\n",
    "        query: {input}, schema: {schema}\n",
    "            \"\"\"\n",
    "       \n",
    "            \n",
    "qaPrompt = PromptTemplate(input_variables=[\"context\", \"question\", \"input\", \"schema\"], template=QA_GENERATION_TEMPLATE)\n",
    "\n",
    "qaPromptChain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=qaPrompt\n",
    ")   \n",
    "\n",
    "# function is used to extract the query from the message, schema is a global variable\n",
    "def queryExtractor(msg: AIMessage):\n",
    "    # print(msg)\n",
    "    query = msg[\"intermediate_steps\"][0][\"query\"]\n",
    "    question = msg[\"query\"]\n",
    "    msg = {\"input\": query, \"schema\": schema, \"question\": question}\n",
    "    return msg\n",
    "\n",
    "# function is used to execute the cypher query\n",
    "def executeCypher(msg: AIMessage):\n",
    "    # print(msg)\n",
    "    query = msg[\"input\"]\n",
    "    query = query.replace(\"cypher\", \"\")\n",
    "    result = graph.query(query)\n",
    "    # result = pd.DataFrame(result)    \n",
    "    return { \"context\" : result , \"question\": msg[\"question\"], \"input\": msg[\"input\"], \"schema\": msg[\"schema\"]}\n",
    "\n",
    "final_chain = cypherqachain | queryExtractor | confidenceChain | agent | executeCypher | qaPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (c:cloudRoleName)-[r:AZURE_DEPENDS_ON]->(s:SQL)\n",
      "RETURN c.id, COUNT(r) AS azureDependencyCount\n",
      "ORDER BY azureDependencyCount DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe question appears to be related to a Cypher query for a Neo4j database. It aims to find the cloudRoleName node (`c`) that has the highest number of `AZURE_DEPENDS_ON` relationships to `SQL` nodes (`s`). The query returns the `id` of the `cloudRoleName` node and the count of these relationships, ordered by the count in descending order, and limits the results to the top one.\n",
      "\n",
      "Here is a step-by-step explanation:\n",
      "\n",
      "1. **MATCH (c:cloudRoleName)-[r:AZURE_DEPENDS_ON]->(s:SQL)**: This part of the query matches all patterns where a `cloudRoleName` node has an `AZURE_DEPENDS_ON` relationship to an `SQL` node.\n",
      "  \n",
      "2. **RETURN c.id, COUNT(r) AS azureDependencyCount**: This part returns the `id` of the `cloudRoleName` node and the count of `AZURE_DEPENDS_ON` relationships as `azureDependencyCount`.\n",
      "\n",
      "3. **ORDER BY azureDependencyCount DESC**: This part orders the results by the count of `AZURE_DEPENDS_ON` relationships in descending order.\n",
      "\n",
      "4. **LIMIT 1**: This part limits the results to only the top result.\n",
      "\n",
      "The query is already correctly structured to achieve its goal. If there are any specific issues or further questions about this query, please let me know!\n",
      "\n",
      "Thought: The query is already correctly structured. However, if there is a specific concern or a need for further clarification, I should ask for more details.\n",
      "Action: human\n",
      "Action Input: Is there a specific aspect of this Cypher query you are concerned about, or do you need further clarification on its functionality?\u001b[0m\n",
      "\n",
      "Is there a specific aspect of this Cypher query you are concerned about, or do you need further clarification on its functionality?\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mno\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems like there is no further clarification needed since the query is already correctly structured and you responded with \"no\" to any specific concerns. \n",
      "\n",
      "Final Answer: The Cypher query provided is correctly structured to find the `cloudRoleName` node that has the highest number of `AZURE_DEPENDS_ON` relationships to `SQL` nodes. It returns the `id` of that `cloudRoleName` node and the count of these relationships, ordered by the count in descending order, and limits the result to the top one.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'cypher\\nMATCH (c:cloudRoleName)-[r:AZURE_DEPENDS_ON]->(s:SQL)\\nRETURN c.id, COUNT(r) AS azureDependencyCount\\nORDER BY azureDependencyCount DESC\\nLIMIT 1\\n', 'schema': 'Node properties are the following:\\ncloudRoleName {id: STRING},SQL {id: STRING}\\nRelationship properties are the following:\\nDEPENDS_ON {counter: INTEGER, operation_Name: STRING, duration: FLOAT, itemType: STRING, operationId: STRING, type: STRING, id: STRING},INPROC_TT {operation_Name: STRING, duration: FLOAT, itemType: STRING, id: STRING, counter: INTEGER, operationId: STRING, type: STRING},AZURE_DEPENDS_ON {itemType: STRING, operation_Name: STRING, id: STRING, operationId: STRING, type: STRING, duration: FLOAT, counter: INTEGER}\\nThe relationships are the following:\\n(:cloudRoleName)-[:DEPENDS_ON]->(:cloudRoleName),(:cloudRoleName)-[:INPROC_TT]->(:cloudRoleName),(:cloudRoleName)-[:AZURE_DEPENDS_ON]->(:SQL)', 'question': 'which nodes has max azure dependencies', 'text': '```json\\n{\\n  \"score\": 5,\\n  \"reason\": \"The query accurately matches the cloudRoleName nodes that have AZURE_DEPENDS_ON relationships with SQL nodes. It correctly counts these relationships and orders the results to find the node with the maximum dependencies.\",\\n  \"assumptions\": \"The provided node and relationship properties are assumed to be correctly defined and relevant.\"\\n}\\n```', 'output': 'The Cypher query provided is correctly structured to find the `cloudRoleName` node that has the highest number of `AZURE_DEPENDS_ON` relationships to `SQL` nodes. It returns the `id` of that `cloudRoleName` node and the count of these relationships, ordered by the count in descending order, and limits the result to the top one.'}\n",
      "############ Final Answer ############\n",
      "- The node with the maximum Azure dependencies is `people-api`, which has 23 Azure dependencies.\n",
      "\n",
      "### Assumptions Made:\n",
      "1. The query provided was designed to find the node (`cloudRoleName`) with the highest count of `AZURE_DEPENDS_ON` relationships to `SQL` nodes.\n",
      "2. The context result indicates that `people-api` was the node returned by the query, with an `azureDependencyCount` of 23, meaning it has 23 `AZURE_DEPENDS_ON` relationships.\n",
      "3. The schema details further confirm that `AZURE_DEPENDS_ON` relationships are between `cloudRoleName` and `SQL` nodes, and the count of these relationships was used to determine the node with the maximum dependencies.\n"
     ]
    }
   ],
   "source": [
    "result = final_chain.invoke({\"query\": \"which nodes has max azure dependencies\"})\n",
    "print(\"############ Final Answer ############\")\n",
    "print(result['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
