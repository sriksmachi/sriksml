{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/sriksmachi/sriksml/blob/main/language-models/transformers_001.ipynb",
      "authorship_tag": "ABX9TyM2o8Gc4cb9lrxRTiSp2nBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriksmachi/sriksml/blob/main/language-models/transformers_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymvAUlN6lfrO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import matmul, cast, float32,sqrt, math, transpose\n",
        "from tensorflow import convert_to_tensor, string\n",
        "from keras.backend import softmax\n",
        "from numpy import random\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, Layer, Dropout\n",
        "from tensorflow.data import Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "_fGjw2YZ_BLF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DotProductAttention(Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(DotProductAttention, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, queries, keys, values, d_k, mask=None):\n",
        "    scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
        "    if mask is not None:\n",
        "      scores += (mask * -1e9)\n",
        "    weights = softmax(scores)\n",
        "    attention_weights = matmul(weights, values)\n",
        "    return attention_weights"
      ],
      "metadata": {
        "id": "IfR6vWNuAQbP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the DotProductAttention\n",
        "\n",
        "d_k = 64\n",
        "d_v = 64\n",
        "batch_size = 64\n",
        "input_seq_len = 10\n",
        "\n",
        "queries = random.random((batch_size, input_seq_len, d_k))\n",
        "keys = random.random((batch_size, input_seq_len, d_k))\n",
        "values = random.random((batch_size, input_seq_len, d_v))\n",
        "\n",
        "attention = DotProductAttention()\n",
        "attention_weights = attention(queries, keys, values, d_k)\n",
        "print(queries.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIh3KZA1B6b4",
        "outputId": "f183e03d-3971-4678-b4de-e5090c6d1fc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "  def __init__(self, n_heads, d_k, d_v, d_model, **kwargs):\n",
        "    super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "    self.n_heads = n_heads\n",
        "    self.attention = DotProductAttention()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.W_q = tf.keras.layers.Dense(d_k)\n",
        "    self.W_k = tf.keras.layers.Dense(d_k)\n",
        "    self.W_v = tf.keras.layers.Dense(d_v)\n",
        "    self.W_o = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def reshape_tensor(self, x, heads, flag):\n",
        "    if flag:\n",
        "      x = tf.reshape(x, shape = (x.shape[0], x.shape[1], heads, -1))\n",
        "      x = transpose(x, perm=[0, 2, 1, 3])\n",
        "    else:\n",
        "      x = transpose(x, perm=(0, 2, 1, 3))\n",
        "      x = tf.reshape(x, shape=(x.shape[0], x.shape[1], -1))\n",
        "    return x\n",
        "\n",
        "  def call(self, queries, keys, values, mask=None):\n",
        "    # this converts the queries to shape (batch_size, heads, input_length, -1)\n",
        "    q_reshaped = self.reshape_tensor(self.W_q(queries), self.n_heads, True)\n",
        "    # this converts the keys to shape (batch_size, heads, input_length, -1)\n",
        "    k_reshaped = self.reshape_tensor(self.W_k(keys), self.n_heads, True)\n",
        "    # this converts the values to shape (batch_size, heads, input_length, -1)\n",
        "    v_reshaped = self.reshape_tensor(self.W_v(values), self.n_heads, True)\n",
        "    # compute attention weights in parallel, reshapes to (batch_size, heads, input_length, -1)\n",
        "    o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
        "    o = self.reshape_tensor(o_reshaped, self.n_heads, False)\n",
        "    o = self.W_o(o)\n",
        "    return o\n"
      ],
      "metadata": {
        "id": "yez0zfzr_h64"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the above code\n",
        "n_heads = 4\n",
        "d_k = 64\n",
        "d_v = 64\n",
        "d_model = 512 # embedding size\n",
        "batch_size = 64\n",
        "input_seq_len = 10\n",
        "\n",
        "# 4, 64, 64, 512\n",
        "multihead_attention = MultiHeadAttention(n_heads, d_k, d_v, d_model)\n",
        "# 64, 10, 64\n",
        "queries = random.random((batch_size, input_seq_len, d_k))\n",
        "keys = random.random((batch_size, input_seq_len, d_k))\n",
        "values = random.random((batch_size, input_seq_len, d_v))\n",
        "\n",
        "attention_weights = multihead_attention(queries, keys, values)\n",
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWXO5VnbHbQ3",
        "outputId": "05bd7574-4b9f-4d38-d07c-5d5cb2365379"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Embedding\n",
        "\n",
        "class PositionalEmbeddingLayer(Layer):\n",
        "  def __init__(self, max_seq_len, vocab_size, output_dim, **kwargs):\n",
        "    super(PositionalEmbeddingLayer, self).__init__(**kwargs)\n",
        "    self.word_embedding_layer = Embedding(vocab_size, output_dim)\n",
        "    self.position_embedding_layer = Embedding(max_seq_len, output_dim)\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.output_dim = output_dim\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "  def call(self, inputs):\n",
        "    position_indices = tf.range(0, tf.shape(inputs)[-1], delta=1)\n",
        "    embedded_words = self.word_embedding_layer(inputs)\n",
        "    embedded_positions = self.position_embedding_layer(position_indices)\n",
        "    return embedded_words + embedded_positions"
      ],
      "metadata": {
        "id": "OUmDv5MuIAO2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_embedding_layer = PositionalEmbeddingLayer(10, 1000, 512)\n",
        "print(my_embedding_layer(tf.constant([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUHfhO9UWwTn",
        "outputId": "c75dd0da-2c8a-4d49-86f5-6297517f2cb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(Layer):\n",
        "  def __init__(self, d_model, d_ff, **kwargs):\n",
        "    super(FeedForward, self).__init__(**kwargs)\n",
        "    self.d_fc1 = tf.keras.layers.Dense(d_ff)\n",
        "    self.d_fc2 = tf.keras.layers.Dense(d_model)\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.d_fc1(x)\n",
        "    x = self.d_fc2(self.activation(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "XAmJ_GS0W3TW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalization(Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(Normalization, self).__init__(**kwargs)\n",
        "    self.layer_Norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x, sublayer_x):\n",
        "    return self.layer_Norm(x + sublayer_x)"
      ],
      "metadata": {
        "id": "8q4m9Z5nZ5C4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "class EncoderLayer(Layer):\n",
        "  def __init__(self, sequence_length, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "    super(EncoderLayer, self).__init__(**kwargs)\n",
        "    self.build(input_shape=[None, sequence_length, d_model])\n",
        "    self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "    self.dropout1 = Dropout(rate)\n",
        "    self.norm1 = Normalization()\n",
        "    self.feed_forward = FeedForward(d_model, d_ff)\n",
        "    self.dropout2 = Dropout(rate)\n",
        "    self.norm2 = Normalization()\n",
        "    self.d_model = d_model\n",
        "    self.sequence_length = sequence_length\n",
        "\n",
        "  def build_graph(self):\n",
        "    input_layer = Input(shape=[self.sequence_length, self.d_model])\n",
        "    return Model(inputs = [input_layer], outputs = self.call(input_layer, None, True))\n",
        "\n",
        "  def call(self, x, padding_mask, training):\n",
        "    # expected output length - batch_size, sequence_length, d_model\n",
        "    multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
        "    multihead_output = self.dropout1(multihead_output, training=training)\n",
        "    add_norm_output = self.norm1(x, multihead_output)\n",
        "    feed_forward_output = self.feed_forward(add_norm_output)\n",
        "    feed_forward_output = self.dropout2(feed_forward_output, training=training)\n",
        "    return self.norm2(add_norm_output, feed_forward_output)"
      ],
      "metadata": {
        "id": "Mv2dLw3uZ5LZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "  def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
        "    super(Encoder, self).__init__(**kwargs)\n",
        "    self.pos_encoding = PositionalEmbeddingLayer(sequence_length, vocab_size, d_model)\n",
        "    self.dropout = Dropout(rate)\n",
        "    self.encoder_layers = [EncoderLayer(sequence_length, h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
        "\n",
        "  def call(self, inputs, padding_mask, training):\n",
        "    x = self.pos_encoding(inputs)\n",
        "    x = self.dropout(x, training=training)\n",
        "    for encoder_layer in self.encoder_layers:\n",
        "      x = encoder_layer(x, padding_mask, training)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Y6QcpGeXcvsD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the above code\n",
        "n_heads = 4\n",
        "d_k = 64\n",
        "d_v = 64\n",
        "d_model = 512 # embedding size\n",
        "batch_size = 64\n",
        "input_seq_len = 10\n",
        "\n",
        "encoder = Encoder(1000, 10, n_heads, d_k, d_v, d_model, 2048, 6, 0.1)\n",
        "print(encoder(tf.random.uniform((batch_size, input_seq_len)), None, training=False).shape)\n",
        "# 64, 10, 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXQsqVp_dK9b",
        "outputId": "ebb65aea-cbf8-4f03-e7cd-50d16b10df95"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(Layer):\n",
        "  def __init__(self, sequence_length, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "    super(DecoderLayer, self).__init__(**kwargs)\n",
        "    self.build(input_shape=[None, sequence_length, d_model])\n",
        "    self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "    self.dropout1 = Dropout(rate)\n",
        "    self.norm1 = Normalization()\n",
        "    self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "    self.dropout2 = Dropout(rate)\n",
        "    self.norm2 = Normalization()\n",
        "    self.feed_forward = FeedForward(d_model, d_ff)\n",
        "    self.dropout3 = Dropout(rate)\n",
        "    self.norm3 = Normalization()\n",
        "    self.d_model = d_model\n",
        "    self.sequence_length = sequence_length\n",
        "\n",
        "  def build_graph(self):\n",
        "    input_layer = Input(shape=[self.sequence_length, self.d_model])\n",
        "    return Model(inputs = [input_layer], outputs = self.call(input_layer, None, True))\n",
        "\n",
        "  def call(self, x, encoder_output, padding_mask, look_ahead_mask, training):\n",
        "    # expected output length - batch_size, sequence_length, d_model\n",
        "    multihead_output1 = self.multihead_attention1(x, x, x, look_ahead_mask)\n",
        "    multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
        "    add_norm_output1 = self.norm1(x, multihead_output1)\n",
        "    multihead_output2 = self.multihead_attention2(add_norm_output1, encoder_output, encoder_output, padding_mask)\n",
        "    multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
        "    norm_output2 = self.norm2(add_norm_output1, multihead_output2)\n",
        "    feed_forward_output = self.feed_forward(norm_output2)\n",
        "    feed_forward_output = self.dropout3(feed_forward_output, training=training)\n",
        "    return self.norm3(norm_output2, feed_forward_output)"
      ],
      "metadata": {
        "id": "NCTW2tHodn7l"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
        "    super(Decoder, self).__init__(**kwargs)\n",
        "    self.pos_encoding = PositionalEmbeddingLayer(sequence_length, vocab_size, d_model)\n",
        "    self.dropout = Dropout(rate)\n",
        "    self.decoder_layers = [DecoderLayer(sequence_length, h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
        "\n",
        "  def call(self, inputs, encoder_output, padding_mask, look_ahead_mask, training):\n",
        "    x = self.pos_encoding(inputs)\n",
        "    x = self.dropout(x, training=training)\n",
        "    for decoder_layer in self.decoder_layers:\n",
        "      x = decoder_layer(x, encoder_output, padding_mask, look_ahead_mask, training)\n",
        "    return x"
      ],
      "metadata": {
        "id": "69rTAm93ffov"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the above code\n",
        "n_heads = 4\n",
        "d_k = 64\n",
        "d_v = 64\n",
        "d_model = 512 # embedding size\n",
        "batch_size = 64\n",
        "input_seq_len = 10\n",
        "\n",
        "decoder = Decoder(1000, 10, n_heads, d_k, d_v, d_model, 2048, 6, 0.1)\n",
        "print(decoder(tf.random.uniform((batch_size, input_seq_len)),  tf.random.uniform((batch_size, input_seq_len, d_model)), None, True).shape)\n",
        "# 64, 10, 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw2cyBlNf6aK",
        "outputId": "936f44be-42c7-47d5-ea18-0e2076f8d3c0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import math, cast, float32\n",
        "from numpy import array\n",
        "\n",
        "def padding_mask(input):\n",
        "  # returns tensor with True for positions with value as 0\n",
        "  mask = math.equal(input, 0)\n",
        "  # converts false/true to numbers\n",
        "  mask = cast(mask, float32)\n",
        "  return mask\n",
        "\n",
        "padding_mask(array([1, 2, 3, 0, 0, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4bEck1P6oj3",
        "outputId": "fcc32e8a-02c3-4c99-b8a4-dfaed2fc549c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([0., 0., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import linalg, ones\n",
        "\n",
        "def look_ahead_mask(shape):\n",
        "  # mask out future entries by replace with 1.0\n",
        "  mask = 1- linalg.band_part(ones((shape, shape)), -1, 0)\n",
        "  return mask\n",
        "\n",
        "# the ones values mask out the values that the decoder must not see\n",
        "# the prediction of every word should depend on word before that only\n",
        "print(look_ahead_mask(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g2MeHn4zorM",
        "outputId": "5665e6c1-432d-47c4-c206-8617a4e2c315"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow import maximum, newaxis\n",
        "\n",
        "class TransformerModel(Model):\n",
        "  def __init__(self, enc_seq_vocab_size, dec_seq_vocab_size, enc_seq_len, dec_seq_len, h, d_k, d_v, d_model, d_ff_inner, n, rate, **kwargs):\n",
        "    super(TransformerModel, self).__init__(**kwargs)\n",
        "    self.encoder = Encoder(enc_seq_vocab_size, enc_seq_len, h, d_k, d_v, d_model, d_ff_inner, n, rate)\n",
        "    self.decoder = Decoder(dec_seq_vocab_size, dec_seq_len, h, d_k, d_v, d_model, d_ff_inner, n, rate)\n",
        "    self.model_last_layer = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def padding_mask(input):\n",
        "    # returns tensor with True for positions with value as 0\n",
        "    mask = math.equal(input, 0)\n",
        "    # converts false/true to numbers\n",
        "    mask = cast(mask, float32)\n",
        "    return mask[:, newaxis, newaxis, :]\n",
        "\n",
        "  def look_ahead_mask(shape):\n",
        "    # mask out future entries by replace with 1.0\n",
        "    mask = 1- linalg.band_part(ones((shape, shape)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "  def call(self, encoder_input, decoder_input, training):\n",
        "    enc_padding_mask = self.padding_mask(encoder_input)\n",
        "\n",
        "    dec_padding_mask = self.padding_mask(decoder_input)\n",
        "    dec_look_ahead_mask = self.look_ahead_mask(decoder_input.shape[1])\n",
        "    dec_look_ahead_mask = maximum(dec_padding_mask, dec_look_ahead_mask)\n",
        "\n",
        "\n",
        "    encoder_output = self.encoder(encoder_input, enc_padding_mask, training)\n",
        "    decoder_output = self.decoder(decoder_input, encoder_output, dec_look_ahead_mask, dec_padding_mask, training)\n",
        "    model_output = self.model_last_layer(decoder_output)\n",
        "    return model_output\n"
      ],
      "metadata": {
        "id": "Soc3yLaW0ikK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_vocab_size = 20 # Vocabulary size for the encoder\n",
        "dec_vocab_size = 20 # Vocabulary size for the decoder\n",
        "\n",
        "enc_seq_length = 5  # Maximum length of the input sequence\n",
        "dec_seq_length = 5  # Maximum length of the target sequence\n",
        "\n",
        "h = 8  # Number of self-attention heads\n",
        "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
        "d_v = 64  # Dimensionality of the linearly projected values\n",
        "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
        "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
        "n = 6  # Number of layers in the encoder stack\n",
        "\n",
        "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n",
        "\n",
        "# Create model\n",
        "training_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
        "# encoder = EncoderLayer(enc_seq_length, h, d_k, d_v, d_model, d_ff, dropout_rate)\n",
        "# # encoder.build_graph().summary()\n",
        "\n",
        "# decoder = DecoderLayer(dec_seq_length, h, d_k, d_v, d_model, d_ff, dropout_rate)\n",
        "# decoder.build_graph().summary()"
      ],
      "metadata": {
        "id": "Y-7PqLIi5D5o",
        "outputId": "8ac64680-a287-48f2-ba95-4d21de071292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-df28f3c5edd6>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtraining_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-2a5184e288a9>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-2a5184e288a9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, padding_mask, training)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# expected output length - batch_size, sequence_length, d_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmultihead_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultihead_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmultihead_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultihead_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0madd_norm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultihead_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filess06rcff.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, queries, keys, values, mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mq_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mk_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mv_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filemcjracda.py\u001b[0m in \u001b[0;36mtf__reshape_tensor\u001b[0;34m(self, x, heads, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filemcjracda.py\u001b[0m in \u001b[0;36mif_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0;32mnonlocal\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"multi_head_attention_76\" (type MultiHeadAttention).\n\nin user code:\n\n    File \"<ipython-input-8-85c7cdd60b08>\", line 24, in call  *\n        q_reshaped = self.reshape_tensor(self.W_q(queries), self.n_heads, True)\n    File \"<ipython-input-8-85c7cdd60b08>\", line 15, in reshape_tensor  *\n        x = tf.reshape(x, shape = (x.shape[0], x.shape[1], heads, -1))\n\n    TypeError: Failed to convert elements of (None, 5, 8, -1) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n\n\nCall arguments received by layer \"multi_head_attention_76\" (type MultiHeadAttention):\n  • queries=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • keys=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • values=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# download dataset provided by Anki: https://www.manythings.org/anki/\n",
        "text_file = tf.keras.utils.get_file(\n",
        "    fname=\"fra-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"fra.txt\"\n",
        "\n",
        "def normalize(line):\n",
        "    \"\"\"Normalize a line of text and split into two at the tab character\"\"\"\n",
        "    line = unicodedata.normalize(\"NFKC\", line.strip().lower())\n",
        "    line = re.sub(r\"^([^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
        "    line = re.sub(r\"(\\s[^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
        "    line = re.sub(r\"(?!\\s)([^ \\w])$\", r\" \\1\", line)\n",
        "    line = re.sub(r\"(?!\\s)([^ \\w]\\s)\", r\" \\1\", line)\n",
        "    eng, fra = line.split(\"\\t\")\n",
        "    eng = \"[start] \" + eng + \" [end]\"\n",
        "    fra = \"[start] \" + fra + \" [end]\"\n",
        "    return eng, fra\n",
        "\n",
        "# normalize each line and separate into English and French\n",
        "with open(text_file) as fp:\n",
        "    text_pairs = [normalize(line) for line in fp]\n",
        "\n",
        "# print some samples\n",
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))\n",
        "\n",
        "with open(\"text_pairs.pickle\", \"wb\") as fp:\n",
        "    pickle.dump(text_pairs, fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXVcdS4gkNoH",
        "outputId": "d68b803c-7b9f-4672-bad1-7de3baaeb93c"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[start] i really miss you all . [end]', '[start] vous me manquez vraiment tous . [end]')\n",
            "('[start] tom and mary leave tomorrow . [end]', '[start] tom et mary partent demain . [end]')\n",
            "(\"[start] i don't think it'll rain tomorrow . [end]\", \"[start] je ne crois pas qu'il va pleuvoir demain . [end]\")\n",
            "('[start] a dead leaf fell to the ground . [end]', '[start] une feuille morte tomba au sol . [end]')\n",
            "('[start] are you ready ? [end]', '[start] êtes-vous prête  ?  [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from numpy.random import shuffle\n"
      ],
      "metadata": {
        "id": "sd_0iwI7j-O6"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import convert_to_tensor, int64\n",
        "\n",
        "class PrepareDataset:\n",
        "  def __init__(self, **kwargs):\n",
        "    super(PrepareDataset, self).__init__(**kwargs)\n",
        "    self.n_sentences = 1000\n",
        "    self.train_split = 0.9\n",
        "\n",
        "  def create_tokenizer(self, dataset):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(dataset)\n",
        "    return tokenizer\n",
        "\n",
        "  def find_seq_length(self, dataset):\n",
        "    return max(len(s.split()) for s in dataset)\n",
        "\n",
        "  def find_vocab_size(self, tokenizer, dataset):\n",
        "    tokenizer.fit_on_texts(dataset)\n",
        "    return len(tokenizer.word_index) + 1\n",
        "\n",
        "  def __call__(self, filename, **kwargs):\n",
        "    clean_data = load(open(filename, 'rb'))\n",
        "    dataset = clean_data[:self.n_sentences]\n",
        "    shuffle(dataset)\n",
        "    train = dataset[:int(self.train_split * self.n_sentences)]\n",
        "    test = dataset[int(self.train_split * self.n_sentences):]\n",
        "\n",
        "    enc_seq_tokenizer = self.create_tokenizer(train[:, 0])\n",
        "    enc_seq_len = self.find_seq_length(train[:, 0])\n",
        "    enc_seq_vocab_size = self.find_vocab_size(enc_seq_tokenizer, train[:, 0])\n",
        "\n",
        "    trainX = enc_seq_tokenizer.texts_to_sequences(train[:, 0])\n",
        "    trainX = pad_sequences(trainX, maxlen=enc_seq_len, padding='post')\n",
        "    trainX = convert_to_tensor(trainX, dtype=int64)\n",
        "\n",
        "    dec_seq_tokenizer = self.create_tokenizer(train[:, 1])\n",
        "    dec_seq_len = self.find_seq_length(train[:, 1])\n",
        "    dec_seq_vocab_size = self.find_vocab_size(dec_seq_tokenizer, train[:, 1])\n",
        "\n",
        "    trainY = dec_seq_tokenizer.texts_to_sequences(train[:, 1])\n",
        "    trainY = pad_sequences(trainY, maxlen=dec_seq_len, padding='post')\n",
        "    trainY = convert_to_tensor(trainY, dtype=int64)\n",
        "\n",
        "    return trainX, trainY, train, enc_seq_len, dec_seq_len, enc_seq_vocab_size, dec_seq_vocab_size"
      ],
      "metadata": {
        "id": "tMubKI2Mqkw8"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PrepareDataset()\n",
        "trainX, trainY, train, enc_seq_len, dec_seq_len, enc_seq_vocab_size, dec_seq_vocab_size = dataset(\"/english-german-both.pkl\")"
      ],
      "metadata": {
        "id": "p7t9PFD0y00l"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Encoder sequence length', enc_seq_len)\n",
        "print('Decoder sequence length', dec_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cGeZ6YNqxUC",
        "outputId": "aaf729b5-aa8c-459d-dd98-1c76644d9f3e"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder sequence length 5\n",
            "Decoder sequence length 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0ouuapM40vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}